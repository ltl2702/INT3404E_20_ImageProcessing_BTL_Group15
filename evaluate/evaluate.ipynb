{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":8389794,"sourceType":"datasetVersion","datasetId":4990230},{"sourceId":8420047,"sourceType":"datasetVersion","datasetId":5012598},{"sourceId":8422360,"sourceType":"datasetVersion","datasetId":5014331},{"sourceId":52269,"sourceType":"modelInstanceVersion","modelInstanceId":39943}],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport random\nimport time\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom PIL import Image\nfrom tempfile import TemporaryDirectory\nimport pandas as pd\nimport csv\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.optim import lr_scheduler\nimport torch.backends.cudnn as cudnn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader, SubsetRandomSampler, random_split\n\nimport torchvision\nfrom torchvision import datasets, models, transforms","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-05-22T07:10:07.517613Z","iopub.execute_input":"2024-05-22T07:10:07.518503Z","iopub.status.idle":"2024-05-22T07:10:14.514821Z","shell.execute_reply.started":"2024-05-22T07:10:07.518460Z","shell.execute_reply":"2024-05-22T07:10:14.513970Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"# Load dataset from folders\nclass FolderDataset(Dataset):\n    def __init__(self, data_dir, transform=None):\n        \"\"\"\n        Initialize the FolderDataset.\n\n        Args:\n            data_dir (str): Path to the dataset directory containing subdirectories for each class.\n            transform (callable, optional): Optional transform to be applied on a sample.\n        \"\"\"\n        self.data_dir = data_dir\n        self.transform = transform\n        self.classes = self._find_classes()\n        self.img_names, self.image_paths, self.labels = self._load_data()\n\n    def _find_classes(self):\n        \"\"\"\n        Find class labels by identifying subdirectories in the dataset directory.\n\n        Returns:\n            list: List of class labels.\n        \"\"\"\n        classes = sorted([d for d in os.listdir(self.data_dir) if os.path.isdir(os.path.join(self.data_dir, d))])\n        return classes\n\n    def _load_data(self):\n        \"\"\"\n        Load data by iterating through each class subdirectory and collecting image paths and labels.\n\n        Returns:\n            tuple: A tuple containing lists of image names, image paths, and corresponding labels.\n        \"\"\"\n        image_paths = []\n        labels = []\n        img_names = []\n        \n        for label in self.classes:\n            class_dir = os.path.join(self.data_dir, label)\n            for img_name in os.listdir(class_dir):\n                img_path = os.path.join(class_dir, img_name)\n                img_names.append(img_name)\n                image_paths.append(img_path)\n                labels.append(int(label))\n        return img_names, image_paths, labels\n\n    def __len__(self):\n        \"\"\"\n        Get the length of the dataset.\n\n        Returns:\n            int: Number of samples in the dataset.\n        \"\"\"\n        return len(self.image_paths)\n\n    def __getitem__(self, idx):\n        \"\"\"\n        Retrieve a sample from the dataset by index.\n\n        Args:\n            idx (int): Index of the sample to retrieve.\n\n        Returns:\n            tuple: A tuple containing the image name, image data, and corresponding label.\n        \"\"\"\n        img_name = self.img_names[idx]\n        img_path = self.image_paths[idx]\n        label = self.labels[idx]\n        label = int(label)\n        image = Image.open(img_path).convert(\"RGB\")\n        if self.transform:\n            image = self.transform(image)\n        return img_name, image, label\n","metadata":{"execution":{"iopub.status.busy":"2024-05-22T07:10:14.516540Z","iopub.execute_input":"2024-05-22T07:10:14.517193Z","iopub.status.idle":"2024-05-22T07:10:14.526710Z","shell.execute_reply.started":"2024-05-22T07:10:14.517164Z","shell.execute_reply":"2024-05-22T07:10:14.525752Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"def find_image_path(image_name, folder_path):\n    \"\"\"\n    Find the path of an image file with the given name in the specified folder.\n\n    Args:\n        image_name (str): The name of the image file without extension.\n        folder_path (str): The path to the folder containing the image file.\n\n    Returns:\n        str or None: The path of the image file if found, otherwise None.\n    \"\"\"\n    # List of common image file extensions\n    extensions = ['.jpg', '.jpeg', '.png']\n\n    # Iterate through each extension to check if the image file exists\n    for ext in extensions:\n        img_path = os.path.join(folder_path, image_name + ext)\n        if os.path.exists(img_path):\n            return img_path\n    \n    # If the image file is not found with any of the extensions, return None\n    return None\n","metadata":{"execution":{"iopub.status.busy":"2024-05-22T07:10:14.528403Z","iopub.execute_input":"2024-05-22T07:10:14.528801Z","iopub.status.idle":"2024-05-22T07:10:14.539490Z","shell.execute_reply.started":"2024-05-22T07:10:14.528748Z","shell.execute_reply":"2024-05-22T07:10:14.538515Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"class FromCSVDataset(Dataset):\n    def __init__(self, csv_file, data_dir, transform=None):\n        \"\"\"\n        Initialize the FromCSVDataset.\n\n        Args:\n            csv_file (str): Path to the CSV file containing image information.\n            data_dir (str): Path to the directory containing the image files.\n            transform (callable, optional): Optional transform to be applied on a sample.\n        \"\"\"\n        self.data_dir = data_dir\n        self.transform = transform\n        self.classes = self._find_classes(csv_file)\n        self.image_names, self.labels = self._load_data(csv_file)\n\n    def _find_classes(self, csv_file):\n        \"\"\"\n        Find unique class labels from the CSV file.\n\n        Args:\n            csv_file (str): Path to the CSV file containing image information.\n\n        Returns:\n            list: List of unique class labels.\n        \"\"\"\n        df = pd.read_csv(csv_file)\n        classes = sorted(df['label'].unique())\n        return classes\n\n    def _load_data(self, csv_file):\n        \"\"\"\n        Load image names and labels from the CSV file.\n\n        Args:\n            csv_file (str): Path to the CSV file containing image information.\n\n        Returns:\n            tuple: A tuple containing lists of image names and corresponding labels.\n        \"\"\"\n        df = pd.read_csv(csv_file)\n        image_names = df['image_name'].tolist()\n        labels = df['label'].tolist()\n        return image_names, labels\n\n    def __len__(self):\n        \"\"\"\n        Get the length of the dataset.\n\n        Returns:\n            int: Number of samples in the dataset.\n        \"\"\"\n        return len(self.image_names)\n\n    def __getitem__(self, idx):\n        \"\"\"\n        Retrieve a sample from the dataset by index.\n\n        Args:\n            idx (int): Index of the sample to retrieve.\n\n        Returns:\n            tuple: A tuple containing the image name, image data, and corresponding label.\n        \"\"\"\n        image_name = str(self.image_names[idx])\n        \n        img_path = find_image_path(image_name, self.data_dir)\n        \n        if not img_path:\n            raise FileNotFoundError(f\"No valid image file found for {image_name} with supported extensions {['.jpg', '.jpeg', '.png']}\")\n        \n        label = int(self.labels[idx])\n        \n        try:\n            image = Image.open(img_path).convert(\"RGB\")\n        except FileNotFoundError:\n            print(f\"File not found: {img_path}\")\n            raise\n        except UnidentifiedImageError:\n            print(f\"Cannot identify image file: {img_path}\")\n            raise\n        except Exception as e:\n            print(f\"Unexpected error loading image {img_path}: {e}\")\n            raise\n\n        if self.transform:\n            try:\n                image = self.transform(image)\n            except Exception as e:\n                print(f\"Error applying transform to image {img_path}: {e}\")\n                raise\n\n        return image_name, image, label\n","metadata":{"execution":{"iopub.status.busy":"2024-05-22T07:10:14.541770Z","iopub.execute_input":"2024-05-22T07:10:14.542427Z","iopub.status.idle":"2024-05-22T07:10:14.555062Z","shell.execute_reply.started":"2024-05-22T07:10:14.542388Z","shell.execute_reply":"2024-05-22T07:10:14.554150Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# Data transformation\ntransform = transforms.Compose([\n        transforms.Resize((224, 224)),  \n        transforms.ToTensor(),\n        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])","metadata":{"execution":{"iopub.status.busy":"2024-05-22T07:10:14.556282Z","iopub.execute_input":"2024-05-22T07:10:14.556669Z","iopub.status.idle":"2024-05-22T07:10:14.566877Z","shell.execute_reply.started":"2024-05-22T07:10:14.556636Z","shell.execute_reply":"2024-05-22T07:10:14.565748Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# Location of data and csv file\ncsv_file = '/kaggle/input/wb-data/wb_recognition_dataset/val/labels.csv'\ndata_dir = '/kaggle/input/wb-data/wb_recognition_dataset/val/images'","metadata":{"execution":{"iopub.status.busy":"2024-05-22T07:10:14.567877Z","iopub.execute_input":"2024-05-22T07:10:14.568171Z","iopub.status.idle":"2024-05-22T07:10:14.579474Z","shell.execute_reply.started":"2024-05-22T07:10:14.568141Z","shell.execute_reply":"2024-05-22T07:10:14.578662Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# Test dataset (use suitable Dataset class)\ntest_dataset = FromCSVDataset(csv_file, data_dir, transform)","metadata":{"execution":{"iopub.status.busy":"2024-05-22T07:10:14.580669Z","iopub.execute_input":"2024-05-22T07:10:14.581058Z","iopub.status.idle":"2024-05-22T07:10:14.617578Z","shell.execute_reply.started":"2024-05-22T07:10:14.581025Z","shell.execute_reply":"2024-05-22T07:10:14.616499Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# Dataloader iterators\ntest_dataloader = DataLoader(test_dataset, batch_size = 32, shuffle = False, num_workers=4, pin_memory = True)","metadata":{"execution":{"iopub.status.busy":"2024-05-22T07:10:14.621620Z","iopub.execute_input":"2024-05-22T07:10:14.621960Z","iopub.status.idle":"2024-05-22T07:10:14.628670Z","shell.execute_reply.started":"2024-05-22T07:10:14.621926Z","shell.execute_reply":"2024-05-22T07:10:14.625661Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# Check number of images and labels\ntest_dataset_size = len(test_dataset)\nprint('Number of images in test dataset: ', len(test_dataset))\nprint('Number of labels in test dataset: ',len(test_dataset.classes))","metadata":{"execution":{"iopub.status.busy":"2024-05-22T07:10:14.630098Z","iopub.execute_input":"2024-05-22T07:10:14.630524Z","iopub.status.idle":"2024-05-22T07:10:14.638891Z","shell.execute_reply.started":"2024-05-22T07:10:14.630451Z","shell.execute_reply":"2024-05-22T07:10:14.637633Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"Number of images in test dataset:  1392\nNumber of labels in test dataset:  595\n","output_type":"stream"}]},{"cell_type":"code","source":"# Number of classes\nnum_classes = 2139  ","metadata":{"execution":{"iopub.status.busy":"2024-05-22T07:10:14.641890Z","iopub.execute_input":"2024-05-22T07:10:14.642724Z","iopub.status.idle":"2024-05-22T07:10:14.646840Z","shell.execute_reply.started":"2024-05-22T07:10:14.642693Z","shell.execute_reply":"2024-05-22T07:10:14.645708Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"pip install efficientnet-pytorch","metadata":{"execution":{"iopub.status.busy":"2024-05-22T07:10:14.648400Z","iopub.execute_input":"2024-05-22T07:10:14.648753Z","iopub.status.idle":"2024-05-22T07:10:29.546579Z","shell.execute_reply.started":"2024-05-22T07:10:14.648723Z","shell.execute_reply":"2024-05-22T07:10:29.545227Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  pid, fd = os.forkpty()\n","output_type":"stream"},{"name":"stdout","text":"Collecting efficientnet-pytorch\n  Downloading efficientnet_pytorch-0.7.1.tar.gz (21 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from efficientnet-pytorch) (2.1.2+cpu)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch->efficientnet-pytorch) (3.13.1)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch->efficientnet-pytorch) (4.9.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->efficientnet-pytorch) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->efficientnet-pytorch) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->efficientnet-pytorch) (3.1.2)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch->efficientnet-pytorch) (2024.2.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->efficientnet-pytorch) (2.1.3)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->efficientnet-pytorch) (1.3.0)\nBuilding wheels for collected packages: efficientnet-pytorch\n  Building wheel for efficientnet-pytorch (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for efficientnet-pytorch: filename=efficientnet_pytorch-0.7.1-py3-none-any.whl size=16428 sha256=f848b3085307cf7a632aaa4bb5f1c0c52637483be231c83df71ee936b0b6ec36\n  Stored in directory: /root/.cache/pip/wheels/03/3f/e9/911b1bc46869644912bda90a56bcf7b960f20b5187feea3baf\nSuccessfully built efficientnet-pytorch\nInstalling collected packages: efficientnet-pytorch\nSuccessfully installed efficientnet-pytorch-0.7.1\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"# Load pretrained model\nfrom efficientnet_pytorch import EfficientNet\nmodel = EfficientNet.from_pretrained('efficientnet-b0')\nnum_ftrs = model._fc.in_features\nmodel._fc = nn.Linear(num_ftrs, num_classes)\n\n# Move to gpu \ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)","metadata":{"execution":{"iopub.status.busy":"2024-05-22T07:10:29.548171Z","iopub.execute_input":"2024-05-22T07:10:29.548518Z","iopub.status.idle":"2024-05-22T07:10:31.433417Z","shell.execute_reply.started":"2024-05-22T07:10:29.548486Z","shell.execute_reply":"2024-05-22T07:10:31.432329Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stderr","text":"Downloading: \"https://github.com/lukemelas/EfficientNet-PyTorch/releases/download/1.0/efficientnet-b0-355c32eb.pth\" to /root/.cache/torch/hub/checkpoints/efficientnet-b0-355c32eb.pth\n100%|██████████| 20.4M/20.4M [00:00<00:00, 51.9MB/s]","output_type":"stream"},{"name":"stdout","text":"Loaded pretrained weights for efficientnet-b0\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"EfficientNet(\n  (_conv_stem): Conv2dStaticSamePadding(\n    3, 32, kernel_size=(3, 3), stride=(2, 2), bias=False\n    (static_padding): ZeroPad2d((0, 1, 0, 1))\n  )\n  (_bn0): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n  (_blocks): ModuleList(\n    (0): MBConvBlock(\n      (_depthwise_conv): Conv2dStaticSamePadding(\n        32, 32, kernel_size=(3, 3), stride=[1, 1], groups=32, bias=False\n        (static_padding): ZeroPad2d((1, 1, 1, 1))\n      )\n      (_bn1): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n      (_se_reduce): Conv2dStaticSamePadding(\n        32, 8, kernel_size=(1, 1), stride=(1, 1)\n        (static_padding): Identity()\n      )\n      (_se_expand): Conv2dStaticSamePadding(\n        8, 32, kernel_size=(1, 1), stride=(1, 1)\n        (static_padding): Identity()\n      )\n      (_project_conv): Conv2dStaticSamePadding(\n        32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False\n        (static_padding): Identity()\n      )\n      (_bn2): BatchNorm2d(16, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n      (_swish): MemoryEfficientSwish()\n    )\n    (1): MBConvBlock(\n      (_expand_conv): Conv2dStaticSamePadding(\n        16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False\n        (static_padding): Identity()\n      )\n      (_bn0): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n      (_depthwise_conv): Conv2dStaticSamePadding(\n        96, 96, kernel_size=(3, 3), stride=[2, 2], groups=96, bias=False\n        (static_padding): ZeroPad2d((0, 1, 0, 1))\n      )\n      (_bn1): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n      (_se_reduce): Conv2dStaticSamePadding(\n        96, 4, kernel_size=(1, 1), stride=(1, 1)\n        (static_padding): Identity()\n      )\n      (_se_expand): Conv2dStaticSamePadding(\n        4, 96, kernel_size=(1, 1), stride=(1, 1)\n        (static_padding): Identity()\n      )\n      (_project_conv): Conv2dStaticSamePadding(\n        96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False\n        (static_padding): Identity()\n      )\n      (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n      (_swish): MemoryEfficientSwish()\n    )\n    (2): MBConvBlock(\n      (_expand_conv): Conv2dStaticSamePadding(\n        24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False\n        (static_padding): Identity()\n      )\n      (_bn0): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n      (_depthwise_conv): Conv2dStaticSamePadding(\n        144, 144, kernel_size=(3, 3), stride=(1, 1), groups=144, bias=False\n        (static_padding): ZeroPad2d((1, 1, 1, 1))\n      )\n      (_bn1): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n      (_se_reduce): Conv2dStaticSamePadding(\n        144, 6, kernel_size=(1, 1), stride=(1, 1)\n        (static_padding): Identity()\n      )\n      (_se_expand): Conv2dStaticSamePadding(\n        6, 144, kernel_size=(1, 1), stride=(1, 1)\n        (static_padding): Identity()\n      )\n      (_project_conv): Conv2dStaticSamePadding(\n        144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False\n        (static_padding): Identity()\n      )\n      (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n      (_swish): MemoryEfficientSwish()\n    )\n    (3): MBConvBlock(\n      (_expand_conv): Conv2dStaticSamePadding(\n        24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False\n        (static_padding): Identity()\n      )\n      (_bn0): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n      (_depthwise_conv): Conv2dStaticSamePadding(\n        144, 144, kernel_size=(5, 5), stride=[2, 2], groups=144, bias=False\n        (static_padding): ZeroPad2d((1, 2, 1, 2))\n      )\n      (_bn1): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n      (_se_reduce): Conv2dStaticSamePadding(\n        144, 6, kernel_size=(1, 1), stride=(1, 1)\n        (static_padding): Identity()\n      )\n      (_se_expand): Conv2dStaticSamePadding(\n        6, 144, kernel_size=(1, 1), stride=(1, 1)\n        (static_padding): Identity()\n      )\n      (_project_conv): Conv2dStaticSamePadding(\n        144, 40, kernel_size=(1, 1), stride=(1, 1), bias=False\n        (static_padding): Identity()\n      )\n      (_bn2): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n      (_swish): MemoryEfficientSwish()\n    )\n    (4): MBConvBlock(\n      (_expand_conv): Conv2dStaticSamePadding(\n        40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False\n        (static_padding): Identity()\n      )\n      (_bn0): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n      (_depthwise_conv): Conv2dStaticSamePadding(\n        240, 240, kernel_size=(5, 5), stride=(1, 1), groups=240, bias=False\n        (static_padding): ZeroPad2d((2, 2, 2, 2))\n      )\n      (_bn1): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n      (_se_reduce): Conv2dStaticSamePadding(\n        240, 10, kernel_size=(1, 1), stride=(1, 1)\n        (static_padding): Identity()\n      )\n      (_se_expand): Conv2dStaticSamePadding(\n        10, 240, kernel_size=(1, 1), stride=(1, 1)\n        (static_padding): Identity()\n      )\n      (_project_conv): Conv2dStaticSamePadding(\n        240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False\n        (static_padding): Identity()\n      )\n      (_bn2): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n      (_swish): MemoryEfficientSwish()\n    )\n    (5): MBConvBlock(\n      (_expand_conv): Conv2dStaticSamePadding(\n        40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False\n        (static_padding): Identity()\n      )\n      (_bn0): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n      (_depthwise_conv): Conv2dStaticSamePadding(\n        240, 240, kernel_size=(3, 3), stride=[2, 2], groups=240, bias=False\n        (static_padding): ZeroPad2d((0, 1, 0, 1))\n      )\n      (_bn1): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n      (_se_reduce): Conv2dStaticSamePadding(\n        240, 10, kernel_size=(1, 1), stride=(1, 1)\n        (static_padding): Identity()\n      )\n      (_se_expand): Conv2dStaticSamePadding(\n        10, 240, kernel_size=(1, 1), stride=(1, 1)\n        (static_padding): Identity()\n      )\n      (_project_conv): Conv2dStaticSamePadding(\n        240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False\n        (static_padding): Identity()\n      )\n      (_bn2): BatchNorm2d(80, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n      (_swish): MemoryEfficientSwish()\n    )\n    (6-7): 2 x MBConvBlock(\n      (_expand_conv): Conv2dStaticSamePadding(\n        80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False\n        (static_padding): Identity()\n      )\n      (_bn0): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n      (_depthwise_conv): Conv2dStaticSamePadding(\n        480, 480, kernel_size=(3, 3), stride=(1, 1), groups=480, bias=False\n        (static_padding): ZeroPad2d((1, 1, 1, 1))\n      )\n      (_bn1): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n      (_se_reduce): Conv2dStaticSamePadding(\n        480, 20, kernel_size=(1, 1), stride=(1, 1)\n        (static_padding): Identity()\n      )\n      (_se_expand): Conv2dStaticSamePadding(\n        20, 480, kernel_size=(1, 1), stride=(1, 1)\n        (static_padding): Identity()\n      )\n      (_project_conv): Conv2dStaticSamePadding(\n        480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False\n        (static_padding): Identity()\n      )\n      (_bn2): BatchNorm2d(80, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n      (_swish): MemoryEfficientSwish()\n    )\n    (8): MBConvBlock(\n      (_expand_conv): Conv2dStaticSamePadding(\n        80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False\n        (static_padding): Identity()\n      )\n      (_bn0): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n      (_depthwise_conv): Conv2dStaticSamePadding(\n        480, 480, kernel_size=(5, 5), stride=[1, 1], groups=480, bias=False\n        (static_padding): ZeroPad2d((2, 2, 2, 2))\n      )\n      (_bn1): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n      (_se_reduce): Conv2dStaticSamePadding(\n        480, 20, kernel_size=(1, 1), stride=(1, 1)\n        (static_padding): Identity()\n      )\n      (_se_expand): Conv2dStaticSamePadding(\n        20, 480, kernel_size=(1, 1), stride=(1, 1)\n        (static_padding): Identity()\n      )\n      (_project_conv): Conv2dStaticSamePadding(\n        480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False\n        (static_padding): Identity()\n      )\n      (_bn2): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n      (_swish): MemoryEfficientSwish()\n    )\n    (9-10): 2 x MBConvBlock(\n      (_expand_conv): Conv2dStaticSamePadding(\n        112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False\n        (static_padding): Identity()\n      )\n      (_bn0): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n      (_depthwise_conv): Conv2dStaticSamePadding(\n        672, 672, kernel_size=(5, 5), stride=(1, 1), groups=672, bias=False\n        (static_padding): ZeroPad2d((2, 2, 2, 2))\n      )\n      (_bn1): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n      (_se_reduce): Conv2dStaticSamePadding(\n        672, 28, kernel_size=(1, 1), stride=(1, 1)\n        (static_padding): Identity()\n      )\n      (_se_expand): Conv2dStaticSamePadding(\n        28, 672, kernel_size=(1, 1), stride=(1, 1)\n        (static_padding): Identity()\n      )\n      (_project_conv): Conv2dStaticSamePadding(\n        672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False\n        (static_padding): Identity()\n      )\n      (_bn2): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n      (_swish): MemoryEfficientSwish()\n    )\n    (11): MBConvBlock(\n      (_expand_conv): Conv2dStaticSamePadding(\n        112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False\n        (static_padding): Identity()\n      )\n      (_bn0): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n      (_depthwise_conv): Conv2dStaticSamePadding(\n        672, 672, kernel_size=(5, 5), stride=[2, 2], groups=672, bias=False\n        (static_padding): ZeroPad2d((1, 2, 1, 2))\n      )\n      (_bn1): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n      (_se_reduce): Conv2dStaticSamePadding(\n        672, 28, kernel_size=(1, 1), stride=(1, 1)\n        (static_padding): Identity()\n      )\n      (_se_expand): Conv2dStaticSamePadding(\n        28, 672, kernel_size=(1, 1), stride=(1, 1)\n        (static_padding): Identity()\n      )\n      (_project_conv): Conv2dStaticSamePadding(\n        672, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n        (static_padding): Identity()\n      )\n      (_bn2): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n      (_swish): MemoryEfficientSwish()\n    )\n    (12-14): 3 x MBConvBlock(\n      (_expand_conv): Conv2dStaticSamePadding(\n        192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False\n        (static_padding): Identity()\n      )\n      (_bn0): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n      (_depthwise_conv): Conv2dStaticSamePadding(\n        1152, 1152, kernel_size=(5, 5), stride=(1, 1), groups=1152, bias=False\n        (static_padding): ZeroPad2d((2, 2, 2, 2))\n      )\n      (_bn1): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n      (_se_reduce): Conv2dStaticSamePadding(\n        1152, 48, kernel_size=(1, 1), stride=(1, 1)\n        (static_padding): Identity()\n      )\n      (_se_expand): Conv2dStaticSamePadding(\n        48, 1152, kernel_size=(1, 1), stride=(1, 1)\n        (static_padding): Identity()\n      )\n      (_project_conv): Conv2dStaticSamePadding(\n        1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n        (static_padding): Identity()\n      )\n      (_bn2): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n      (_swish): MemoryEfficientSwish()\n    )\n    (15): MBConvBlock(\n      (_expand_conv): Conv2dStaticSamePadding(\n        192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False\n        (static_padding): Identity()\n      )\n      (_bn0): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n      (_depthwise_conv): Conv2dStaticSamePadding(\n        1152, 1152, kernel_size=(3, 3), stride=[1, 1], groups=1152, bias=False\n        (static_padding): ZeroPad2d((1, 1, 1, 1))\n      )\n      (_bn1): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n      (_se_reduce): Conv2dStaticSamePadding(\n        1152, 48, kernel_size=(1, 1), stride=(1, 1)\n        (static_padding): Identity()\n      )\n      (_se_expand): Conv2dStaticSamePadding(\n        48, 1152, kernel_size=(1, 1), stride=(1, 1)\n        (static_padding): Identity()\n      )\n      (_project_conv): Conv2dStaticSamePadding(\n        1152, 320, kernel_size=(1, 1), stride=(1, 1), bias=False\n        (static_padding): Identity()\n      )\n      (_bn2): BatchNorm2d(320, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n      (_swish): MemoryEfficientSwish()\n    )\n  )\n  (_conv_head): Conv2dStaticSamePadding(\n    320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False\n    (static_padding): Identity()\n  )\n  (_bn1): BatchNorm2d(1280, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n  (_avg_pooling): AdaptiveAvgPool2d(output_size=1)\n  (_dropout): Dropout(p=0.2, inplace=False)\n  (_fc): Linear(in_features=1280, out_features=2139, bias=True)\n  (_swish): MemoryEfficientSwish()\n)"},"metadata":{}}]},{"cell_type":"code","source":"def test_model(model, dataloader, csv_result):\n    # Set the model to evaluation mode\n    model.eval()\n\n    # Keep track of the number of correct predictions\n    running_corrects = 0\n    \n    # A list to store the results\n    results = []\n\n    for image_names, inputs, labels in dataloader:\n        inputs, labels = inputs.to(device), labels.to(device)\n\n        # Get the predicted labels\n        outputs = model(inputs)\n        _, preds = torch.max(outputs, 1)\n\n        # Accumulate the number of correct predictions\n        running_corrects += torch.sum(preds == labels.data)\n        \n        # Store the image names and predicted labels in the results list\n        for image_name, pred in zip(image_names, preds):\n            # use image_name.item() for csv\n            results.append([image_name, pred.item()])\n            \n    # Save the results to a CSV file \n    try:\n        with open(csv_result, 'w', newline='') as file:\n            writer = csv.writer(file)\n            writer.writerow(['image_name', 'label'])\n            writer.writerows(results)\n        print(f'Results saved successfully to {csv_result}')\n    except Exception as e:\n        print(f'Error saving results to CSV: {e}')\n\n     # Calculate the accuracy\n    epoch_acc = running_corrects.double() / test_dataset_size\n\n    print(f'Accuracy: {epoch_acc:.4f}')\n            ","metadata":{"execution":{"iopub.status.busy":"2024-05-22T07:10:31.434719Z","iopub.execute_input":"2024-05-22T07:10:31.435267Z","iopub.status.idle":"2024-05-22T07:10:31.443909Z","shell.execute_reply.started":"2024-05-22T07:10:31.435222Z","shell.execute_reply":"2024-05-22T07:10:31.442847Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"# Location of saved model \nsaved_model_path = '/kaggle/input/efficientnetb0-1/pytorch/efficientnet_b0_1/4/efficientNetb0-imagenet-11-best.pt'","metadata":{"execution":{"iopub.status.busy":"2024-05-22T07:10:31.445072Z","iopub.execute_input":"2024-05-22T07:10:31.445377Z","iopub.status.idle":"2024-05-22T07:10:31.455457Z","shell.execute_reply.started":"2024-05-22T07:10:31.445348Z","shell.execute_reply":"2024-05-22T07:10:31.454660Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"try:\n    if torch.cuda.is_available():\n        model.load_state_dict(torch.load(saved_model_path))\n    else:\n        model.load_state_dict(torch.load(saved_model_path, map_location=torch.device('cpu')))\n    print('Loaded saved model successfully')\nexcept FileNotFoundError:\n    print('File not found')\nexcept Exception as e:\n    print(f'An error occurred: {e}')","metadata":{"execution":{"iopub.status.busy":"2024-05-22T07:10:31.456910Z","iopub.execute_input":"2024-05-22T07:10:31.457384Z","iopub.status.idle":"2024-05-22T07:10:31.806996Z","shell.execute_reply.started":"2024-05-22T07:10:31.457349Z","shell.execute_reply":"2024-05-22T07:10:31.805825Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"Loaded saved model successfully\n","output_type":"stream"}]},{"cell_type":"code","source":"csv_result_path = '/kaggle/working/result_folder.csv'","metadata":{"execution":{"iopub.status.busy":"2024-05-22T07:10:31.808131Z","iopub.execute_input":"2024-05-22T07:10:31.808409Z","iopub.status.idle":"2024-05-22T07:10:31.813547Z","shell.execute_reply.started":"2024-05-22T07:10:31.808386Z","shell.execute_reply":"2024-05-22T07:10:31.812217Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"try:\n    test_model(model, test_dataloader, csv_result_path)\nexcept Exception as e:\n    print(f'An error occurred during model testing: {e}')\n    ","metadata":{"execution":{"iopub.status.busy":"2024-05-22T07:10:31.814710Z","iopub.execute_input":"2024-05-22T07:10:31.815036Z","iopub.status.idle":"2024-05-22T07:11:32.962821Z","shell.execute_reply.started":"2024-05-22T07:10:31.815005Z","shell.execute_reply":"2024-05-22T07:11:32.961626Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\n/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\n","output_type":"stream"},{"name":"stdout","text":"Results saved successfully to /kaggle/working/result_folder.csv\nAccuracy: 0.9511\n","output_type":"stream"}]}]}