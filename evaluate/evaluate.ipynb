{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":8389794,"sourceType":"datasetVersion","datasetId":4990230},{"sourceId":8420047,"sourceType":"datasetVersion","datasetId":5012598},{"sourceId":8422360,"sourceType":"datasetVersion","datasetId":5014331},{"sourceId":8489589,"sourceType":"datasetVersion","datasetId":5064791},{"sourceId":52269,"sourceType":"modelInstanceVersion","modelInstanceId":39943}],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport random\nimport time\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom PIL import Image, UnidentifiedImageError\nfrom tempfile import TemporaryDirectory\nimport pandas as pd\nimport csv\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.optim import lr_scheduler\nimport torch.backends.cudnn as cudnn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader, SubsetRandomSampler, random_split\n\nimport torchvision\nfrom torchvision import datasets, models, transforms","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-05-29T10:11:51.463641Z","iopub.execute_input":"2024-05-29T10:11:51.464537Z","iopub.status.idle":"2024-05-29T10:11:57.472457Z","shell.execute_reply.started":"2024-05-29T10:11:51.464504Z","shell.execute_reply":"2024-05-29T10:11:57.471623Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"# Load dataset from folder\nclass FolderDataset(Dataset):\n    def __init__(self, data_dir, transform=None):\n        \"\"\"\n        Initialize the FolderDataset.\n\n        Args:\n            data_dir (str): Path to the dataset directory containing subdirectories for each class.\n            transform (callable, optional): Optional transform to be applied on a sample.\n        \"\"\"\n        self.data_dir = data_dir\n        self.transform = transform\n        self.img_names, self.image_paths = self._load_data()\n\n    def _load_data(self):\n        \"\"\"\n        Load data by iterating through each class subdirectory and collecting image paths and labels.\n\n        Returns:\n            tuple: A tuple containing lists of image names, image paths, and corresponding labels.\n        \"\"\"\n        image_paths = []\n        img_names = []\n        \n\n        for img_path in os.listdir(self.data_dir):\n            img_name = int(os.path.splitext(img_path)[0])\n            img_path = os.path.join(self.data_dir, img_path)\n            img_names.append(img_name)\n            image_paths.append(img_path)\n        return img_names, image_paths\n\n    def __len__(self):\n        \"\"\"\n        Get the length of the dataset.\n\n        Returns:\n            int: Number of samples in the dataset.\n        \"\"\"\n        return len(self.image_paths)\n\n    def __getitem__(self, idx):\n        \"\"\"\n        Retrieve a sample from the dataset by index.\n\n        Args:\n            idx (int): Index of the sample to retrieve.\n\n        Returns:\n            tuple: A tuple containing the image name, image data, and corresponding label.\n        \"\"\"\n        img_name = self.img_names[idx]\n        img_path = self.image_paths[idx]\n        try:\n            image = Image.open(img_path).convert(\"RGB\")\n        except FileNotFoundError:\n            print(f\"File not found: {img_path}\")\n            sys.exit(1)  # Exit the program with an error code\n        except UnidentifiedImageError:\n            print(f\"Cannot identify image file: {img_path}\")\n            sys.exit(1)  # Exit the program with an error code\n        except Exception as e:\n            print(f\"Unexpected error loading image {img_path}: {e}\")\n            sys.exit(1)  # Exit the program with an error code\n\n        if self.transform:\n            try:\n                image = self.transform(image)\n            except Exception as e:\n                print(f\"Error applying transform to image {img_path}: {e}\")\n                raise\n        return img_name, image\n","metadata":{"execution":{"iopub.status.busy":"2024-05-29T10:39:13.386729Z","iopub.execute_input":"2024-05-29T10:39:13.387499Z","iopub.status.idle":"2024-05-29T10:39:13.400045Z","shell.execute_reply.started":"2024-05-29T10:39:13.387463Z","shell.execute_reply":"2024-05-29T10:39:13.398880Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"# Data transformation\ntransform = transforms.Compose([\n        transforms.Resize((224, 224)),  \n        transforms.ToTensor(),\n        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])","metadata":{"execution":{"iopub.status.busy":"2024-05-29T10:27:25.282139Z","iopub.execute_input":"2024-05-29T10:27:25.282492Z","iopub.status.idle":"2024-05-29T10:27:25.290242Z","shell.execute_reply.started":"2024-05-29T10:27:25.282461Z","shell.execute_reply":"2024-05-29T10:27:25.289329Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# Location of data and csv file\ndata_dir = '/kaggle/input/wb-data/wb_recognition_dataset/val/images'","metadata":{"execution":{"iopub.status.busy":"2024-05-29T10:27:31.348712Z","iopub.execute_input":"2024-05-29T10:27:31.349395Z","iopub.status.idle":"2024-05-29T10:27:31.353692Z","shell.execute_reply.started":"2024-05-29T10:27:31.349363Z","shell.execute_reply":"2024-05-29T10:27:31.352630Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# Test dataset (use suitable Dataset class)\ntest_dataset = FolderDataset(data_dir, transform)","metadata":{"execution":{"iopub.status.busy":"2024-05-29T10:39:24.174560Z","iopub.execute_input":"2024-05-29T10:39:24.175559Z","iopub.status.idle":"2024-05-29T10:39:24.190421Z","shell.execute_reply.started":"2024-05-29T10:39:24.175524Z","shell.execute_reply":"2024-05-29T10:39:24.189629Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"# Dataloader iterators\ntest_dataloader = DataLoader(test_dataset, batch_size = 32, shuffle = False, num_workers=4, pin_memory = True)","metadata":{"execution":{"iopub.status.busy":"2024-05-29T10:39:26.156671Z","iopub.execute_input":"2024-05-29T10:39:26.157050Z","iopub.status.idle":"2024-05-29T10:39:26.162158Z","shell.execute_reply.started":"2024-05-29T10:39:26.157021Z","shell.execute_reply":"2024-05-29T10:39:26.161194Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"# Check number of images and labels\ntest_dataset_size = len(test_dataset)\nprint('Number of images in test dataset: ', len(test_dataset))\n","metadata":{"execution":{"iopub.status.busy":"2024-05-29T10:31:40.096554Z","iopub.execute_input":"2024-05-29T10:31:40.097278Z","iopub.status.idle":"2024-05-29T10:31:40.102185Z","shell.execute_reply.started":"2024-05-29T10:31:40.097246Z","shell.execute_reply":"2024-05-29T10:31:40.101232Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"Number of images in test dataset:  1392\n","output_type":"stream"}]},{"cell_type":"code","source":"# Number of classes\nnum_classes = 2139  ","metadata":{"execution":{"iopub.status.busy":"2024-05-29T10:31:44.136096Z","iopub.execute_input":"2024-05-29T10:31:44.136439Z","iopub.status.idle":"2024-05-29T10:31:44.140746Z","shell.execute_reply.started":"2024-05-29T10:31:44.136407Z","shell.execute_reply":"2024-05-29T10:31:44.139739Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"pip install efficientnet-pytorch","metadata":{"execution":{"iopub.status.busy":"2024-05-29T10:31:45.811470Z","iopub.execute_input":"2024-05-29T10:31:45.812408Z","iopub.status.idle":"2024-05-29T10:32:01.334176Z","shell.execute_reply.started":"2024-05-29T10:31:45.812373Z","shell.execute_reply":"2024-05-29T10:32:01.333032Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"Collecting efficientnet-pytorch\n  Downloading efficientnet_pytorch-0.7.1.tar.gz (21 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from efficientnet-pytorch) (2.1.2)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch->efficientnet-pytorch) (3.13.1)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch->efficientnet-pytorch) (4.9.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->efficientnet-pytorch) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->efficientnet-pytorch) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->efficientnet-pytorch) (3.1.2)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch->efficientnet-pytorch) (2024.2.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->efficientnet-pytorch) (2.1.3)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->efficientnet-pytorch) (1.3.0)\nBuilding wheels for collected packages: efficientnet-pytorch\n  Building wheel for efficientnet-pytorch (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for efficientnet-pytorch: filename=efficientnet_pytorch-0.7.1-py3-none-any.whl size=16428 sha256=a025e64b856f90de8d2dd2a97f44edf41fdfa2424a23d9d0840a235eb5a26bb5\n  Stored in directory: /root/.cache/pip/wheels/03/3f/e9/911b1bc46869644912bda90a56bcf7b960f20b5187feea3baf\nSuccessfully built efficientnet-pytorch\nInstalling collected packages: efficientnet-pytorch\nSuccessfully installed efficientnet-pytorch-0.7.1\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"# Load pretrained model\nfrom efficientnet_pytorch import EfficientNet\nmodel = EfficientNet.from_pretrained('efficientnet-b0')\nnum_ftrs = model._fc.in_features\nmodel._fc = nn.Linear(num_ftrs, num_classes)\n\n# Move to gpu \ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)","metadata":{"execution":{"iopub.status.busy":"2024-05-29T10:32:03.336121Z","iopub.execute_input":"2024-05-29T10:32:03.336396Z","iopub.status.idle":"2024-05-29T10:32:03.512138Z","shell.execute_reply.started":"2024-05-29T10:32:03.336372Z","shell.execute_reply":"2024-05-29T10:32:03.511235Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"Loaded pretrained weights for efficientnet-b0\n","output_type":"stream"},{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"EfficientNet(\n  (_conv_stem): Conv2dStaticSamePadding(\n    3, 32, kernel_size=(3, 3), stride=(2, 2), bias=False\n    (static_padding): ZeroPad2d((0, 1, 0, 1))\n  )\n  (_bn0): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n  (_blocks): ModuleList(\n    (0): MBConvBlock(\n      (_depthwise_conv): Conv2dStaticSamePadding(\n        32, 32, kernel_size=(3, 3), stride=[1, 1], groups=32, bias=False\n        (static_padding): ZeroPad2d((1, 1, 1, 1))\n      )\n      (_bn1): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n      (_se_reduce): Conv2dStaticSamePadding(\n        32, 8, kernel_size=(1, 1), stride=(1, 1)\n        (static_padding): Identity()\n      )\n      (_se_expand): Conv2dStaticSamePadding(\n        8, 32, kernel_size=(1, 1), stride=(1, 1)\n        (static_padding): Identity()\n      )\n      (_project_conv): Conv2dStaticSamePadding(\n        32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False\n        (static_padding): Identity()\n      )\n      (_bn2): BatchNorm2d(16, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n      (_swish): MemoryEfficientSwish()\n    )\n    (1): MBConvBlock(\n      (_expand_conv): Conv2dStaticSamePadding(\n        16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False\n        (static_padding): Identity()\n      )\n      (_bn0): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n      (_depthwise_conv): Conv2dStaticSamePadding(\n        96, 96, kernel_size=(3, 3), stride=[2, 2], groups=96, bias=False\n        (static_padding): ZeroPad2d((0, 1, 0, 1))\n      )\n      (_bn1): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n      (_se_reduce): Conv2dStaticSamePadding(\n        96, 4, kernel_size=(1, 1), stride=(1, 1)\n        (static_padding): Identity()\n      )\n      (_se_expand): Conv2dStaticSamePadding(\n        4, 96, kernel_size=(1, 1), stride=(1, 1)\n        (static_padding): Identity()\n      )\n      (_project_conv): Conv2dStaticSamePadding(\n        96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False\n        (static_padding): Identity()\n      )\n      (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n      (_swish): MemoryEfficientSwish()\n    )\n    (2): MBConvBlock(\n      (_expand_conv): Conv2dStaticSamePadding(\n        24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False\n        (static_padding): Identity()\n      )\n      (_bn0): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n      (_depthwise_conv): Conv2dStaticSamePadding(\n        144, 144, kernel_size=(3, 3), stride=(1, 1), groups=144, bias=False\n        (static_padding): ZeroPad2d((1, 1, 1, 1))\n      )\n      (_bn1): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n      (_se_reduce): Conv2dStaticSamePadding(\n        144, 6, kernel_size=(1, 1), stride=(1, 1)\n        (static_padding): Identity()\n      )\n      (_se_expand): Conv2dStaticSamePadding(\n        6, 144, kernel_size=(1, 1), stride=(1, 1)\n        (static_padding): Identity()\n      )\n      (_project_conv): Conv2dStaticSamePadding(\n        144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False\n        (static_padding): Identity()\n      )\n      (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n      (_swish): MemoryEfficientSwish()\n    )\n    (3): MBConvBlock(\n      (_expand_conv): Conv2dStaticSamePadding(\n        24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False\n        (static_padding): Identity()\n      )\n      (_bn0): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n      (_depthwise_conv): Conv2dStaticSamePadding(\n        144, 144, kernel_size=(5, 5), stride=[2, 2], groups=144, bias=False\n        (static_padding): ZeroPad2d((1, 2, 1, 2))\n      )\n      (_bn1): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n      (_se_reduce): Conv2dStaticSamePadding(\n        144, 6, kernel_size=(1, 1), stride=(1, 1)\n        (static_padding): Identity()\n      )\n      (_se_expand): Conv2dStaticSamePadding(\n        6, 144, kernel_size=(1, 1), stride=(1, 1)\n        (static_padding): Identity()\n      )\n      (_project_conv): Conv2dStaticSamePadding(\n        144, 40, kernel_size=(1, 1), stride=(1, 1), bias=False\n        (static_padding): Identity()\n      )\n      (_bn2): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n      (_swish): MemoryEfficientSwish()\n    )\n    (4): MBConvBlock(\n      (_expand_conv): Conv2dStaticSamePadding(\n        40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False\n        (static_padding): Identity()\n      )\n      (_bn0): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n      (_depthwise_conv): Conv2dStaticSamePadding(\n        240, 240, kernel_size=(5, 5), stride=(1, 1), groups=240, bias=False\n        (static_padding): ZeroPad2d((2, 2, 2, 2))\n      )\n      (_bn1): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n      (_se_reduce): Conv2dStaticSamePadding(\n        240, 10, kernel_size=(1, 1), stride=(1, 1)\n        (static_padding): Identity()\n      )\n      (_se_expand): Conv2dStaticSamePadding(\n        10, 240, kernel_size=(1, 1), stride=(1, 1)\n        (static_padding): Identity()\n      )\n      (_project_conv): Conv2dStaticSamePadding(\n        240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False\n        (static_padding): Identity()\n      )\n      (_bn2): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n      (_swish): MemoryEfficientSwish()\n    )\n    (5): MBConvBlock(\n      (_expand_conv): Conv2dStaticSamePadding(\n        40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False\n        (static_padding): Identity()\n      )\n      (_bn0): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n      (_depthwise_conv): Conv2dStaticSamePadding(\n        240, 240, kernel_size=(3, 3), stride=[2, 2], groups=240, bias=False\n        (static_padding): ZeroPad2d((0, 1, 0, 1))\n      )\n      (_bn1): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n      (_se_reduce): Conv2dStaticSamePadding(\n        240, 10, kernel_size=(1, 1), stride=(1, 1)\n        (static_padding): Identity()\n      )\n      (_se_expand): Conv2dStaticSamePadding(\n        10, 240, kernel_size=(1, 1), stride=(1, 1)\n        (static_padding): Identity()\n      )\n      (_project_conv): Conv2dStaticSamePadding(\n        240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False\n        (static_padding): Identity()\n      )\n      (_bn2): BatchNorm2d(80, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n      (_swish): MemoryEfficientSwish()\n    )\n    (6-7): 2 x MBConvBlock(\n      (_expand_conv): Conv2dStaticSamePadding(\n        80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False\n        (static_padding): Identity()\n      )\n      (_bn0): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n      (_depthwise_conv): Conv2dStaticSamePadding(\n        480, 480, kernel_size=(3, 3), stride=(1, 1), groups=480, bias=False\n        (static_padding): ZeroPad2d((1, 1, 1, 1))\n      )\n      (_bn1): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n      (_se_reduce): Conv2dStaticSamePadding(\n        480, 20, kernel_size=(1, 1), stride=(1, 1)\n        (static_padding): Identity()\n      )\n      (_se_expand): Conv2dStaticSamePadding(\n        20, 480, kernel_size=(1, 1), stride=(1, 1)\n        (static_padding): Identity()\n      )\n      (_project_conv): Conv2dStaticSamePadding(\n        480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False\n        (static_padding): Identity()\n      )\n      (_bn2): BatchNorm2d(80, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n      (_swish): MemoryEfficientSwish()\n    )\n    (8): MBConvBlock(\n      (_expand_conv): Conv2dStaticSamePadding(\n        80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False\n        (static_padding): Identity()\n      )\n      (_bn0): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n      (_depthwise_conv): Conv2dStaticSamePadding(\n        480, 480, kernel_size=(5, 5), stride=[1, 1], groups=480, bias=False\n        (static_padding): ZeroPad2d((2, 2, 2, 2))\n      )\n      (_bn1): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n      (_se_reduce): Conv2dStaticSamePadding(\n        480, 20, kernel_size=(1, 1), stride=(1, 1)\n        (static_padding): Identity()\n      )\n      (_se_expand): Conv2dStaticSamePadding(\n        20, 480, kernel_size=(1, 1), stride=(1, 1)\n        (static_padding): Identity()\n      )\n      (_project_conv): Conv2dStaticSamePadding(\n        480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False\n        (static_padding): Identity()\n      )\n      (_bn2): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n      (_swish): MemoryEfficientSwish()\n    )\n    (9-10): 2 x MBConvBlock(\n      (_expand_conv): Conv2dStaticSamePadding(\n        112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False\n        (static_padding): Identity()\n      )\n      (_bn0): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n      (_depthwise_conv): Conv2dStaticSamePadding(\n        672, 672, kernel_size=(5, 5), stride=(1, 1), groups=672, bias=False\n        (static_padding): ZeroPad2d((2, 2, 2, 2))\n      )\n      (_bn1): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n      (_se_reduce): Conv2dStaticSamePadding(\n        672, 28, kernel_size=(1, 1), stride=(1, 1)\n        (static_padding): Identity()\n      )\n      (_se_expand): Conv2dStaticSamePadding(\n        28, 672, kernel_size=(1, 1), stride=(1, 1)\n        (static_padding): Identity()\n      )\n      (_project_conv): Conv2dStaticSamePadding(\n        672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False\n        (static_padding): Identity()\n      )\n      (_bn2): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n      (_swish): MemoryEfficientSwish()\n    )\n    (11): MBConvBlock(\n      (_expand_conv): Conv2dStaticSamePadding(\n        112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False\n        (static_padding): Identity()\n      )\n      (_bn0): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n      (_depthwise_conv): Conv2dStaticSamePadding(\n        672, 672, kernel_size=(5, 5), stride=[2, 2], groups=672, bias=False\n        (static_padding): ZeroPad2d((1, 2, 1, 2))\n      )\n      (_bn1): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n      (_se_reduce): Conv2dStaticSamePadding(\n        672, 28, kernel_size=(1, 1), stride=(1, 1)\n        (static_padding): Identity()\n      )\n      (_se_expand): Conv2dStaticSamePadding(\n        28, 672, kernel_size=(1, 1), stride=(1, 1)\n        (static_padding): Identity()\n      )\n      (_project_conv): Conv2dStaticSamePadding(\n        672, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n        (static_padding): Identity()\n      )\n      (_bn2): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n      (_swish): MemoryEfficientSwish()\n    )\n    (12-14): 3 x MBConvBlock(\n      (_expand_conv): Conv2dStaticSamePadding(\n        192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False\n        (static_padding): Identity()\n      )\n      (_bn0): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n      (_depthwise_conv): Conv2dStaticSamePadding(\n        1152, 1152, kernel_size=(5, 5), stride=(1, 1), groups=1152, bias=False\n        (static_padding): ZeroPad2d((2, 2, 2, 2))\n      )\n      (_bn1): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n      (_se_reduce): Conv2dStaticSamePadding(\n        1152, 48, kernel_size=(1, 1), stride=(1, 1)\n        (static_padding): Identity()\n      )\n      (_se_expand): Conv2dStaticSamePadding(\n        48, 1152, kernel_size=(1, 1), stride=(1, 1)\n        (static_padding): Identity()\n      )\n      (_project_conv): Conv2dStaticSamePadding(\n        1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n        (static_padding): Identity()\n      )\n      (_bn2): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n      (_swish): MemoryEfficientSwish()\n    )\n    (15): MBConvBlock(\n      (_expand_conv): Conv2dStaticSamePadding(\n        192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False\n        (static_padding): Identity()\n      )\n      (_bn0): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n      (_depthwise_conv): Conv2dStaticSamePadding(\n        1152, 1152, kernel_size=(3, 3), stride=[1, 1], groups=1152, bias=False\n        (static_padding): ZeroPad2d((1, 1, 1, 1))\n      )\n      (_bn1): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n      (_se_reduce): Conv2dStaticSamePadding(\n        1152, 48, kernel_size=(1, 1), stride=(1, 1)\n        (static_padding): Identity()\n      )\n      (_se_expand): Conv2dStaticSamePadding(\n        48, 1152, kernel_size=(1, 1), stride=(1, 1)\n        (static_padding): Identity()\n      )\n      (_project_conv): Conv2dStaticSamePadding(\n        1152, 320, kernel_size=(1, 1), stride=(1, 1), bias=False\n        (static_padding): Identity()\n      )\n      (_bn2): BatchNorm2d(320, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n      (_swish): MemoryEfficientSwish()\n    )\n  )\n  (_conv_head): Conv2dStaticSamePadding(\n    320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False\n    (static_padding): Identity()\n  )\n  (_bn1): BatchNorm2d(1280, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n  (_avg_pooling): AdaptiveAvgPool2d(output_size=1)\n  (_dropout): Dropout(p=0.2, inplace=False)\n  (_fc): Linear(in_features=1280, out_features=2139, bias=True)\n  (_swish): MemoryEfficientSwish()\n)"},"metadata":{}}]},{"cell_type":"code","source":"def test_model(model, dataloader, csv_result):\n    # Set the model to evaluation mode\n    model.eval()\n\n    # A list to store the results\n    results = []\n\n    for image_names, inputs in dataloader:\n        inputs = inputs.to(device)\n\n        # Get the predicted labels\n        outputs = model(inputs)\n        _, preds = torch.max(outputs, 1)\n\n        # Store the image names and predicted labels in the results list\n        for image_name, pred in zip(image_names, preds):\n            # use image_name.item() for csv\n            results.append([image_name.item(), pred.item()])\n    \n    results = sorted(results, key=lambda x: x[0]) \n            \n    # Save the results to a CSV file \n    try:\n        with open(csv_result, 'w', newline='') as file:\n            writer = csv.writer(file)\n            writer.writerow(['image_name', 'label'])\n            writer.writerows(results)\n        print(f'Results saved successfully to {csv_result}')\n    except Exception as e:\n        print(f'Error saving results to CSV: {e}')            ","metadata":{"execution":{"iopub.status.busy":"2024-05-29T10:36:29.412792Z","iopub.execute_input":"2024-05-29T10:36:29.413827Z","iopub.status.idle":"2024-05-29T10:36:29.422508Z","shell.execute_reply.started":"2024-05-29T10:36:29.413791Z","shell.execute_reply":"2024-05-29T10:36:29.421535Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"# Location of saved model \nsaved_model_path = '/kaggle/input/efficientnetb0-1/pytorch/efficientnet_b0_1/4/efficientNetb0-imagenet-11-best.pt'","metadata":{"execution":{"iopub.status.busy":"2024-05-29T10:34:10.245896Z","iopub.execute_input":"2024-05-29T10:34:10.246250Z","iopub.status.idle":"2024-05-29T10:34:10.250698Z","shell.execute_reply.started":"2024-05-29T10:34:10.246221Z","shell.execute_reply":"2024-05-29T10:34:10.249727Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"try:\n    if torch.cuda.is_available():\n        model.load_state_dict(torch.load(saved_model_path))\n    else:\n        model.load_state_dict(torch.load(saved_model_path, map_location=torch.device('cpu')))\n    print('Loaded saved model successfully')\nexcept FileNotFoundError:\n    print('File not found')\nexcept Exception as e:\n    print(f'An error occurred: {e}')","metadata":{"execution":{"iopub.status.busy":"2024-05-29T10:34:13.080564Z","iopub.execute_input":"2024-05-29T10:34:13.081023Z","iopub.status.idle":"2024-05-29T10:34:13.542649Z","shell.execute_reply.started":"2024-05-29T10:34:13.080992Z","shell.execute_reply":"2024-05-29T10:34:13.541413Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"Loaded saved model successfully\n","output_type":"stream"}]},{"cell_type":"code","source":"csv_result_path = '/kaggle/working/result_folder.csv'","metadata":{"execution":{"iopub.status.busy":"2024-05-29T10:34:20.480924Z","iopub.execute_input":"2024-05-29T10:34:20.481276Z","iopub.status.idle":"2024-05-29T10:34:20.485701Z","shell.execute_reply.started":"2024-05-29T10:34:20.481248Z","shell.execute_reply":"2024-05-29T10:34:20.484758Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"try:\n    test_model(model, test_dataloader, csv_result_path)\nexcept Exception as e:\n    print(f'An error occurred during model testing: {e}')\n    ","metadata":{"execution":{"iopub.status.busy":"2024-05-29T10:39:36.524747Z","iopub.execute_input":"2024-05-29T10:39:36.525709Z","iopub.status.idle":"2024-05-29T10:39:38.559786Z","shell.execute_reply.started":"2024-05-29T10:39:36.525653Z","shell.execute_reply":"2024-05-29T10:39:38.558604Z"},"trusted":true},"execution_count":33,"outputs":[{"name":"stdout","text":"Results saved successfully to /kaggle/working/result_folder.csv\n","output_type":"stream"}]}]}