{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":8363588,"sourceType":"datasetVersion","datasetId":4971019},{"sourceId":53054,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":44542}],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport random\nimport time\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom PIL import Image\nfrom tempfile import TemporaryDirectory\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.optim import lr_scheduler\nimport torch.backends.cudnn as cudnn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader, SubsetRandomSampler, random_split\n\nimport torchvision\nfrom torchvision import datasets, models, transforms\n\nimport wandb\n\ncudnn.benchmark = True\nplt.ion()\n\n!wandb login b199ff6d9c0a9f7fc2901490f41b4dacc0ef21d6\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-05-21T13:53:03.047767Z","iopub.execute_input":"2024-05-21T13:53:03.048378Z","iopub.status.idle":"2024-05-21T13:53:12.774932Z","shell.execute_reply.started":"2024-05-21T13:53:03.048334Z","shell.execute_reply":"2024-05-21T13:53:12.773774Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"}]},{"cell_type":"code","source":"# Customed Dataset class\nclass CustomDataset(Dataset):\n    def __init__(self, data_dir, transform=None):\n        self.data_dir = data_dir\n        self.transform = transform\n        self.classes = self._find_classes()\n        self.image_paths, self.labels = self._load_data()\n\n    def _find_classes(self):\n        classes = sorted([d for d in os.listdir(self.data_dir) if os.path.isdir(os.path.join(self.data_dir, d))])\n        return classes\n\n    def _load_data(self):\n        image_paths = []\n        labels = []\n        for label in self.classes:\n            class_dir = os.path.join(self.data_dir, label)\n            for img_name in os.listdir(class_dir):\n                img_path = os.path.join(class_dir, img_name)\n                image_paths.append(img_path)\n                labels.append(int(label))\n        return image_paths, labels\n\n    def __len__(self):\n        return len(self.image_paths)\n\n    def __getitem__(self, idx):\n        img_path = self.image_paths[idx]\n        label = self.labels[idx]\n        label = int(label)\n        image = Image.open(img_path).convert(\"RGB\")\n        if self.transform:\n            image = self.transform(image)\n        return image, label","metadata":{"execution":{"iopub.status.busy":"2024-05-21T13:53:12.777536Z","iopub.execute_input":"2024-05-21T13:53:12.777941Z","iopub.status.idle":"2024-05-21T13:53:12.789058Z","shell.execute_reply.started":"2024-05-21T13:53:12.777904Z","shell.execute_reply":"2024-05-21T13:53:12.787860Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# Parameters\n\n# Change batchsize to fit hardware\nbatch_size = 128\n\n# Training parameters\nnum_classes = 2139  \nlearning_rate = 0.0001\nnum_epochs = 30\n\n# Scheduler\nstep_size = 5\ngamma = 1\n","metadata":{"execution":{"iopub.status.busy":"2024-05-21T13:53:12.790312Z","iopub.execute_input":"2024-05-21T13:53:12.790626Z","iopub.status.idle":"2024-05-21T13:53:12.809821Z","shell.execute_reply.started":"2024-05-21T13:53:12.790599Z","shell.execute_reply":"2024-05-21T13:53:12.808955Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# Location of data\ntrain_dir = '/kaggle/input/wb-recognition-dataset/wb_recognition_dataset/train'\nval_dir = '/kaggle/input/wb-recognition-dataset/wb_recognition_dataset/val'","metadata":{"execution":{"iopub.status.busy":"2024-05-21T13:53:12.812033Z","iopub.execute_input":"2024-05-21T13:53:12.812396Z","iopub.status.idle":"2024-05-21T13:53:12.822659Z","shell.execute_reply.started":"2024-05-21T13:53:12.812370Z","shell.execute_reply":"2024-05-21T13:53:12.821881Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# Data transformations\ndata_transforms = {\n    'train': transforms.Compose([\n        transforms.Resize((224, 224)),  \n        transforms.ToTensor(),\n        transforms.RandomRotation(degrees=15),\n        transforms.ColorJitter(),\n        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n    ]),\n    'val': transforms.Compose([\n        transforms.Resize((224, 224)),\n        transforms.ToTensor(),\n        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n    ]),\n}","metadata":{"execution":{"iopub.status.busy":"2024-05-21T13:53:12.823696Z","iopub.execute_input":"2024-05-21T13:53:12.823962Z","iopub.status.idle":"2024-05-21T13:53:12.832582Z","shell.execute_reply.started":"2024-05-21T13:53:12.823939Z","shell.execute_reply":"2024-05-21T13:53:12.831757Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# Datasets from each folder\nimage_datasets = {\n    'train': CustomDataset(train_dir, data_transforms['train']),\n    'val': CustomDataset(val_dir, data_transforms['val']),\n}\n\n# Dataloader iterators\ndataloaders = {\n    'train': DataLoader(image_datasets['train'], batch_size=batch_size, shuffle=True, num_workers=4, pin_memory = True),\n    'val': DataLoader(image_datasets['val'], batch_size=batch_size, shuffle=False, num_workers=4, pin_memory = True),\n}\n\n# Size of datasets\ndataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}","metadata":{"execution":{"iopub.status.busy":"2024-05-21T13:53:12.833517Z","iopub.execute_input":"2024-05-21T13:53:12.833762Z","iopub.status.idle":"2024-05-21T13:54:11.863831Z","shell.execute_reply.started":"2024-05-21T13:53:12.833740Z","shell.execute_reply":"2024-05-21T13:54:11.862808Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# Number of images and labels\nprint('Number of images in train: ', dataset_sizes['train'])\nprint('Number of labels in train: ',len(image_datasets['train'].classes))\nprint('Number of images in val: ', dataset_sizes['val'])\nprint('Number of labels in val: ', len(image_datasets['val'].classes))","metadata":{"execution":{"iopub.status.busy":"2024-05-21T13:54:11.865338Z","iopub.execute_input":"2024-05-21T13:54:11.865674Z","iopub.status.idle":"2024-05-21T13:54:11.873894Z","shell.execute_reply.started":"2024-05-21T13:54:11.865642Z","shell.execute_reply":"2024-05-21T13:54:11.873019Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"Number of images in train:  56813\nNumber of labels in train:  2130\nNumber of images in val:  1392\nNumber of labels in val:  595\n","output_type":"stream"}]},{"cell_type":"code","source":"#VGG16\nmodel = models.vgg16(weights=models.VGG16_Weights.IMAGENET1K_V1)\n\n# Freeze early layers\nfor param in model.parameters():\n    param.requires_grad = False\nn_inputs = model.classifier[6].in_features\n\n# Add on classifier\nmodel.classifier[6] = nn.Sequential(\nnn.Linear(n_inputs, 256), nn.ReLU(), nn.Dropout(0.2), nn.Linear(256, 2139), nn.LogSoftmax(dim=1))","metadata":{"execution":{"iopub.status.busy":"2024-05-21T13:54:11.875237Z","iopub.execute_input":"2024-05-21T13:54:11.875555Z","iopub.status.idle":"2024-05-21T13:54:17.015432Z","shell.execute_reply.started":"2024-05-21T13:54:11.875525Z","shell.execute_reply":"2024-05-21T13:54:17.014654Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stderr","text":"Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /root/.cache/torch/hub/checkpoints/vgg16-397923af.pth\n100%|██████████| 528M/528M [00:03<00:00, 166MB/s]  \n","output_type":"stream"}]},{"cell_type":"code","source":"# Training loss and optimizer\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=learning_rate)\n\n# Decay the learning rate by 10% every 5 epochs\nscheduler = optim.lr_scheduler.StepLR(optimizer, step_size= step_size, gamma=gamma)","metadata":{"execution":{"iopub.status.busy":"2024-05-21T13:54:17.016582Z","iopub.execute_input":"2024-05-21T13:54:17.016869Z","iopub.status.idle":"2024-05-21T13:54:17.022684Z","shell.execute_reply.started":"2024-05-21T13:54:17.016844Z","shell.execute_reply":"2024-05-21T13:54:17.021839Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"# Move to gpu \ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)\nprint(device)","metadata":{"execution":{"iopub.status.busy":"2024-05-21T13:54:17.025983Z","iopub.execute_input":"2024-05-21T13:54:17.026489Z","iopub.status.idle":"2024-05-21T13:54:17.375722Z","shell.execute_reply.started":"2024-05-21T13:54:17.026466Z","shell.execute_reply":"2024-05-21T13:54:17.374693Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"cuda:0\n","output_type":"stream"}]},{"cell_type":"code","source":"# Check model\nprint(model)","metadata":{"execution":{"iopub.status.busy":"2024-05-21T13:54:17.376964Z","iopub.execute_input":"2024-05-21T13:54:17.377305Z","iopub.status.idle":"2024-05-21T13:54:17.382412Z","shell.execute_reply.started":"2024-05-21T13:54:17.377267Z","shell.execute_reply":"2024-05-21T13:54:17.381519Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"VGG(\n  (features): Sequential(\n    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (1): ReLU(inplace=True)\n    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (3): ReLU(inplace=True)\n    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (6): ReLU(inplace=True)\n    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (8): ReLU(inplace=True)\n    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (11): ReLU(inplace=True)\n    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (13): ReLU(inplace=True)\n    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (15): ReLU(inplace=True)\n    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (18): ReLU(inplace=True)\n    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (20): ReLU(inplace=True)\n    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (22): ReLU(inplace=True)\n    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (25): ReLU(inplace=True)\n    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (27): ReLU(inplace=True)\n    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (29): ReLU(inplace=True)\n    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  )\n  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n  (classifier): Sequential(\n    (0): Linear(in_features=25088, out_features=4096, bias=True)\n    (1): ReLU(inplace=True)\n    (2): Dropout(p=0.5, inplace=False)\n    (3): Linear(in_features=4096, out_features=4096, bias=True)\n    (4): ReLU(inplace=True)\n    (5): Dropout(p=0.5, inplace=False)\n    (6): Sequential(\n      (0): Linear(in_features=4096, out_features=256, bias=True)\n      (1): ReLU()\n      (2): Dropout(p=0.2, inplace=False)\n      (3): Linear(in_features=256, out_features=2139, bias=True)\n      (4): LogSoftmax(dim=1)\n    )\n  )\n)\n","output_type":"stream"}]},{"cell_type":"code","source":"def train_model(model, criterion, optimizer, dataloaders, model_last_pth, model_best_pth, num_epochs):\n    \"\"\"Train a PyTorch Model\n\n    Params\n    --------\n        model (PyTorch model): cnn to train\n        criterion (PyTorch loss): objective to minimize\n        optimizer (PyTorch optimizier): optimizer to compute gradients of model parameters\n        dataloaders (PyTorch dataloader): dataloaders to iterate through\n        model_last_pth, model_best_pth (str ending in '.pt'): file path to save the model state dict\n        num_epochs (int): maximum number of training epochs\n\n    Returns\n    --------\n        model (PyTorch model): trained cnn with best weights\n    \"\"\"\n    \n    # Min validation loss\n    valid_loss_min = np.Inf\n    \n    # Main loop\n    for epoch in range(num_epochs):\n        print(f'Epoch {epoch+1} / {num_epochs}')\n        print('-' * 10)\n        \n        # Go through training and validation phase each epoch\n        for phase in ['train', 'val']:\n            if phase == 'train':\n                model.train()\n            else:\n                model.eval()\n            \n            # Keep track of loss and corrects each epoch\n            running_loss = 0.0\n            running_corrects = 0\n\n            # Training loop\n            for inputs, labels in dataloaders[phase]:\n                inputs, labels = inputs.to(device), labels.to(device)\n                \n                # Clear gradients\n                optimizer.zero_grad()\n                \n                # Predicted outputs and loss of gradients\n                with torch.set_grad_enabled(phase == 'train'):\n                    outputs = model(inputs)\n                    _, preds = torch.max(outputs, 1)\n                    loss = criterion(outputs, labels)\n\n                    # Backpropagation and update parameters\n                    if phase == 'train':\n                        loss.backward()\n                        optimizer.step()\n\n                # Update loss and number of correct predictions\n                running_loss += loss.item() * inputs.size(0)\n                running_corrects += torch.sum(preds == labels.data)\n            \n            # Step the scheduler if in training phase\n            if phase == 'train':\n                scheduler.step()\n            \n            # Calculate loss and accuracy of each epoch\n            epoch_loss = running_loss / dataset_sizes[phase]\n            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n            \n            \n            if phase == 'val':\n                if epoch_loss < valid_loss_min:\n                    valid_loss_min = epoch_loss\n                    torch.save(model.state_dict(), model_best_pth)\n            \n            print(f'{phase}\\t Loss: {epoch_loss:.4f}\\t Accuracy: {epoch_acc:.4f}')\n            \n            wandb.log({f'{phase}_loss': epoch_loss, f'{phase}_acc': epoch_acc})\n        \n        # Save model every epoch\n        torch.save(model.state_dict(), model_last_pth)\n\n    return model","metadata":{"execution":{"iopub.status.busy":"2024-05-21T13:54:17.383583Z","iopub.execute_input":"2024-05-21T13:54:17.383866Z","iopub.status.idle":"2024-05-21T13:54:17.397633Z","shell.execute_reply.started":"2024-05-21T13:54:17.383843Z","shell.execute_reply":"2024-05-21T13:54:17.396591Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"# Path to save model (last and best)\nmodel_last_pth = '/kaggle/working/VGG16-imagenet-2-last.pt'\nmodel_best_pth = '/kaggle/working/VGG16-imagenet-2-best.pt'\n\n# Saved model \nsaved_model_path = '/kaggle/input/vgg16/pytorch/vgg16_v1/1/vgg16-transfer-imagenet-normalization-0.pt'","metadata":{"execution":{"iopub.status.busy":"2024-05-21T16:26:31.925198Z","iopub.execute_input":"2024-05-21T16:26:31.926078Z","iopub.status.idle":"2024-05-21T16:26:31.930846Z","shell.execute_reply.started":"2024-05-21T16:26:31.926037Z","shell.execute_reply":"2024-05-21T16:26:31.929770Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"wandb.init(project='ImageProcessing-project', sync_tensorboard=True)\n\n# Load saved model\ntry:\n    model.load_state_dict(torch.load(saved_model_path))\n    print('Loaded saved model successfully')\nexcept FileNotFoundError:\n    print('File not found')\nexcept Exception as e:\n    print(f'An error occurred: {e}')\n\nprint()\n\nmodel.to(device)\n    \nmodel = train_model(model, criterion, optimizer, dataloaders, model_last_pth, model_best_pth, num_epochs)\n\nwandb.finish()","metadata":{"execution":{"iopub.status.busy":"2024-05-21T16:26:34.503948Z","iopub.execute_input":"2024-05-21T16:26:34.504823Z","iopub.status.idle":"2024-05-21T17:40:31.745970Z","shell.execute_reply.started":"2024-05-21T16:26:34.504790Z","shell.execute_reply":"2024-05-21T17:40:31.743935Z"},"trusted":true},"execution_count":19,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.17.0 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240521_162634-809h4ixx</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/tunglam994/ImageProcessing-project/runs/809h4ixx' target=\"_blank\">rural-morning-67</a></strong> to <a href='https://wandb.ai/tunglam994/ImageProcessing-project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/tunglam994/ImageProcessing-project' target=\"_blank\">https://wandb.ai/tunglam994/ImageProcessing-project</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/tunglam994/ImageProcessing-project/runs/809h4ixx' target=\"_blank\">https://wandb.ai/tunglam994/ImageProcessing-project/runs/809h4ixx</a>"},"metadata":{}},{"name":"stdout","text":"An error occurred: PytorchStreamReader failed locating file data/3: file not found\n\nEpoch 1 / 30\n----------\ntrain\t Loss: 4.8253\t Accuracy: 0.1294\nval\t Loss: 3.8262\t Accuracy: 0.3326\nEpoch 2 / 30\n----------\ntrain\t Loss: 4.8077\t Accuracy: 0.1328\nval\t Loss: 3.8013\t Accuracy: 0.3341\nEpoch 3 / 30\n----------\ntrain\t Loss: 4.7864\t Accuracy: 0.1350\nval\t Loss: 3.7999\t Accuracy: 0.3362\nEpoch 4 / 30\n----------\ntrain\t Loss: 4.7758\t Accuracy: 0.1354\nval\t Loss: 3.7823\t Accuracy: 0.3376\nEpoch 5 / 30\n----------\ntrain\t Loss: 4.7590\t Accuracy: 0.1399\nval\t Loss: 3.7982\t Accuracy: 0.3333\nEpoch 6 / 30\n----------\ntrain\t Loss: 4.7487\t Accuracy: 0.1384\nval\t Loss: 3.7838\t Accuracy: 0.3348\nEpoch 7 / 30\n----------\ntrain\t Loss: 4.7293\t Accuracy: 0.1410\nval\t Loss: 3.7737\t Accuracy: 0.3434\nEpoch 8 / 30\n----------\ntrain\t Loss: 4.7119\t Accuracy: 0.1408\nval\t Loss: 3.7653\t Accuracy: 0.3341\nEpoch 9 / 30\n----------\ntrain\t Loss: 4.6980\t Accuracy: 0.1428\nval\t Loss: 3.7536\t Accuracy: 0.3333\nEpoch 10 / 30\n----------\ntrain\t Loss: 4.6892\t Accuracy: 0.1457\nval\t Loss: 3.7432\t Accuracy: 0.3434\nEpoch 11 / 30\n----------\ntrain\t Loss: 4.6746\t Accuracy: 0.1438\nval\t Loss: 3.7662\t Accuracy: 0.3441\nEpoch 12 / 30\n----------\ntrain\t Loss: 4.6485\t Accuracy: 0.1509\nval\t Loss: 3.7504\t Accuracy: 0.3448\nEpoch 13 / 30\n----------\ntrain\t Loss: 4.6382\t Accuracy: 0.1490\nval\t Loss: 3.7359\t Accuracy: 0.3441\nEpoch 14 / 30\n----------\ntrain\t Loss: 4.6428\t Accuracy: 0.1485\nval\t Loss: 3.7463\t Accuracy: 0.3427\nEpoch 15 / 30\n----------\ntrain\t Loss: 4.6237\t Accuracy: 0.1528\nval\t Loss: 3.7022\t Accuracy: 0.3506\nEpoch 16 / 30\n----------\ntrain\t Loss: 4.6054\t Accuracy: 0.1524\nval\t Loss: 3.7063\t Accuracy: 0.3527\nEpoch 17 / 30\n----------\ntrain\t Loss: 4.6036\t Accuracy: 0.1536\nval\t Loss: 3.7062\t Accuracy: 0.3455\nEpoch 18 / 30\n----------\ntrain\t Loss: 4.5904\t Accuracy: 0.1538\nval\t Loss: 3.7043\t Accuracy: 0.3527\nEpoch 19 / 30\n----------\ntrain\t Loss: 4.5750\t Accuracy: 0.1574\nval\t Loss: 3.7034\t Accuracy: 0.3477\nEpoch 20 / 30\n----------\ntrain\t Loss: 4.5681\t Accuracy: 0.1571\nval\t Loss: 3.7127\t Accuracy: 0.3441\nEpoch 21 / 30\n----------\ntrain\t Loss: 4.5592\t Accuracy: 0.1583\nval\t Loss: 3.6645\t Accuracy: 0.3549\nEpoch 22 / 30\n----------\ntrain\t Loss: 4.5416\t Accuracy: 0.1598\nval\t Loss: 3.6447\t Accuracy: 0.3542\nEpoch 23 / 30\n----------\ntrain\t Loss: 4.5205\t Accuracy: 0.1638\nval\t Loss: 3.6904\t Accuracy: 0.3455\nEpoch 24 / 30\n----------\ntrain\t Loss: 4.5345\t Accuracy: 0.1611\nval\t Loss: 3.6548\t Accuracy: 0.3491\nEpoch 25 / 30\n----------\ntrain\t Loss: 4.5181\t Accuracy: 0.1625\nval\t Loss: 3.6618\t Accuracy: 0.3463\nEpoch 26 / 30\n----------\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[19], line 16\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m()\n\u001b[1;32m     14\u001b[0m model\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m---> 16\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_last_pth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_best_pth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m wandb\u001b[38;5;241m.\u001b[39mfinish()\n","Cell \u001b[0;32mIn[14], line 56\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, criterion, optimizer, dataloaders, model_last_pth, model_best_pth, num_epochs)\u001b[0m\n\u001b[1;32m     53\u001b[0m             optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     55\u001b[0m     \u001b[38;5;66;03m# Update loss and number of correct predictions\u001b[39;00m\n\u001b[0;32m---> 56\u001b[0m     running_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m*\u001b[39m inputs\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     57\u001b[0m     running_corrects \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msum(preds \u001b[38;5;241m==\u001b[39m labels\u001b[38;5;241m.\u001b[39mdata)\n\u001b[1;32m     59\u001b[0m \u001b[38;5;66;03m# Step the scheduler if in training phase\u001b[39;00m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]}]}