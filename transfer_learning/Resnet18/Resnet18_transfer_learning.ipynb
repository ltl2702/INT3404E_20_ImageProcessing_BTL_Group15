{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":8363588,"sourceType":"datasetVersion","datasetId":4971019},{"sourceId":8422360,"sourceType":"datasetVersion","datasetId":5014331}],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport random\nimport time\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom PIL import Image\nfrom tempfile import TemporaryDirectory\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.optim import lr_scheduler\nimport torch.backends.cudnn as cudnn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader, SubsetRandomSampler, random_split\n\nimport torchvision\nfrom torchvision import datasets, models, transforms\n\nimport wandb\n\ncudnn.benchmark = True\nplt.ion()\n\n!wandb login b199ff6d9c0a9f7fc2901490f41b4dacc0ef21d6\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-05-21T12:30:17.600650Z","iopub.execute_input":"2024-05-21T12:30:17.601259Z","iopub.status.idle":"2024-05-21T12:30:25.599244Z","shell.execute_reply.started":"2024-05-21T12:30:17.601221Z","shell.execute_reply":"2024-05-21T12:30:25.598144Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"}]},{"cell_type":"code","source":"# Customed Dataset class\nclass CustomDataset(Dataset):\n    def __init__(self, data_dir, transform=None):\n        self.data_dir = data_dir\n        self.transform = transform\n        self.classes = self._find_classes()\n        self.image_paths, self.labels = self._load_data()\n\n    def _find_classes(self):\n        classes = sorted([d for d in os.listdir(self.data_dir) if os.path.isdir(os.path.join(self.data_dir, d))])\n        return classes\n\n    def _load_data(self):\n        image_paths = []\n        labels = []\n        for label in self.classes:\n            class_dir = os.path.join(self.data_dir, label)\n            for img_name in os.listdir(class_dir):\n                img_path = os.path.join(class_dir, img_name)\n                image_paths.append(img_path)\n                labels.append(int(label))\n        return image_paths, labels\n\n    def __len__(self):\n        return len(self.image_paths)\n\n    def __getitem__(self, idx):\n        img_path = self.image_paths[idx]\n        label = self.labels[idx]\n        label = int(label)\n        image = Image.open(img_path).convert(\"RGB\")\n        if self.transform:\n            image = self.transform(image)\n        return image, label","metadata":{"execution":{"iopub.status.busy":"2024-05-21T12:30:30.372510Z","iopub.execute_input":"2024-05-21T12:30:30.372888Z","iopub.status.idle":"2024-05-21T12:30:30.383774Z","shell.execute_reply.started":"2024-05-21T12:30:30.372852Z","shell.execute_reply":"2024-05-21T12:30:30.382867Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# Parameters\n\n# Change batchsize to fit hardware\nbatch_size = 64\n\n# Training parameters\nnum_classes = 2139  \nlearning_rate = 0.001\nnum_epochs = 100\n\n# Scheduler\nstep_size = 7\ngamma = 0.1\n","metadata":{"execution":{"iopub.status.busy":"2024-05-21T12:30:34.295916Z","iopub.execute_input":"2024-05-21T12:30:34.296260Z","iopub.status.idle":"2024-05-21T12:30:34.301418Z","shell.execute_reply.started":"2024-05-21T12:30:34.296234Z","shell.execute_reply":"2024-05-21T12:30:34.300466Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# Location of data\ntrain_dir = '/kaggle/input/wb-recognition-dataset/wb_recognition_dataset/train'\nval_dir = '/kaggle/input/wb-recognition-dataset/wb_recognition_dataset/val'","metadata":{"execution":{"iopub.status.busy":"2024-05-21T12:30:38.439972Z","iopub.execute_input":"2024-05-21T12:30:38.440324Z","iopub.status.idle":"2024-05-21T12:30:38.444744Z","shell.execute_reply.started":"2024-05-21T12:30:38.440297Z","shell.execute_reply":"2024-05-21T12:30:38.443743Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# Data transformations\ndata_transforms = {\n    'train': transforms.Compose([\n        transforms.Resize((224, 224)),  \n        transforms.ToTensor(),\n        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n    ]),\n    'val': transforms.Compose([\n        transforms.Resize((224, 224)),\n        transforms.ToTensor(),\n        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n    ]),\n}","metadata":{"execution":{"iopub.status.busy":"2024-05-21T12:30:44.058496Z","iopub.execute_input":"2024-05-21T12:30:44.058843Z","iopub.status.idle":"2024-05-21T12:30:44.065343Z","shell.execute_reply.started":"2024-05-21T12:30:44.058818Z","shell.execute_reply":"2024-05-21T12:30:44.064239Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# Datasets from each folder\nimage_datasets = {\n    'train': CustomDataset(train_dir, data_transforms['train']),\n    'val': CustomDataset(val_dir, data_transforms['val']),\n}\n\n# Dataloader iterators\ndataloaders = {\n    'train': DataLoader(image_datasets['train'], batch_size=batch_size, shuffle=True, num_workers=4, pin_memory = True),\n    'val': DataLoader(image_datasets['val'], batch_size=batch_size, shuffle=False, num_workers=4, pin_memory = True),\n}\n\n# Size of datasets\ndataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}","metadata":{"execution":{"iopub.status.busy":"2024-05-21T12:30:47.724520Z","iopub.execute_input":"2024-05-21T12:30:47.724895Z","iopub.status.idle":"2024-05-21T12:31:29.479601Z","shell.execute_reply.started":"2024-05-21T12:30:47.724868Z","shell.execute_reply":"2024-05-21T12:31:29.478679Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# Number of images and labels\nprint('Number of images in train: ', dataset_sizes['train'])\nprint('Number of labels in train: ',len(image_datasets['train'].classes))\nprint('Number of images in val: ', dataset_sizes['val'])\nprint('Number of labels in val: ', len(image_datasets['val'].classes))","metadata":{"execution":{"iopub.status.busy":"2024-05-21T12:31:55.752255Z","iopub.execute_input":"2024-05-21T12:31:55.752630Z","iopub.status.idle":"2024-05-21T12:31:55.758226Z","shell.execute_reply.started":"2024-05-21T12:31:55.752604Z","shell.execute_reply":"2024-05-21T12:31:55.757324Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Number of images in train:  56813\nNumber of labels in train:  2130\nNumber of images in val:  1392\nNumber of labels in val:  595\n","output_type":"stream"}]},{"cell_type":"code","source":"# pip install efficientnet-pytorch","metadata":{"execution":{"iopub.status.busy":"2024-05-21T12:31:59.087188Z","iopub.execute_input":"2024-05-21T12:31:59.087563Z","iopub.status.idle":"2024-05-21T12:31:59.091927Z","shell.execute_reply.started":"2024-05-21T12:31:59.087531Z","shell.execute_reply":"2024-05-21T12:31:59.090911Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# from efficientnet_pytorch import EfficientNet\n# Load pretrained model\n# model = EfficientNet.from_pretrained('efficientnet-b0')\nmodel = torchvision.models.resnet18(weights='DEFAULT')\n\n# Replace fully connected layer\nnum_ftrs = model.fc.in_features\nmodel.fc = nn.Linear(num_ftrs, num_classes)","metadata":{"execution":{"iopub.status.busy":"2024-05-21T12:32:02.531774Z","iopub.execute_input":"2024-05-21T12:32:02.532184Z","iopub.status.idle":"2024-05-21T12:32:03.386420Z","shell.execute_reply.started":"2024-05-21T12:32:02.532137Z","shell.execute_reply":"2024-05-21T12:32:03.385294Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stderr","text":"Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n100%|██████████| 44.7M/44.7M [00:00<00:00, 105MB/s] \n","output_type":"stream"}]},{"cell_type":"code","source":"# Training loss and optimizer\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum = 0.9)\n\n# Decay the learning rate by 10% every 7 epochs\nscheduler = optim.lr_scheduler.StepLR(optimizer, step_size= step_size, gamma=gamma)","metadata":{"execution":{"iopub.status.busy":"2024-05-21T12:32:11.111759Z","iopub.execute_input":"2024-05-21T12:32:11.112122Z","iopub.status.idle":"2024-05-21T12:32:11.118206Z","shell.execute_reply.started":"2024-05-21T12:32:11.112091Z","shell.execute_reply":"2024-05-21T12:32:11.117313Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"# Move to gpu \ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)\nprint(device)","metadata":{"execution":{"iopub.status.busy":"2024-05-21T12:32:14.783315Z","iopub.execute_input":"2024-05-21T12:32:14.783704Z","iopub.status.idle":"2024-05-21T12:32:14.983182Z","shell.execute_reply.started":"2024-05-21T12:32:14.783673Z","shell.execute_reply":"2024-05-21T12:32:14.982209Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"cuda:0\n","output_type":"stream"}]},{"cell_type":"code","source":"# Check model\nprint(model)","metadata":{"execution":{"iopub.status.busy":"2024-05-21T12:32:18.482499Z","iopub.execute_input":"2024-05-21T12:32:18.483218Z","iopub.status.idle":"2024-05-21T12:32:18.488511Z","shell.execute_reply.started":"2024-05-21T12:32:18.483166Z","shell.execute_reply":"2024-05-21T12:32:18.487434Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"ResNet(\n  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (relu): ReLU(inplace=True)\n  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n  (layer1): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (layer2): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (layer3): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (layer4): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n  (fc): Linear(in_features=512, out_features=2139, bias=True)\n)\n","output_type":"stream"}]},{"cell_type":"code","source":"def train_model(model, criterion, optimizer, dataloaders, model_last_pth, model_best_pth, num_epochs):\n    \"\"\"Train a PyTorch Model\n\n    Params\n    --------\n        model (PyTorch model): cnn to train\n        criterion (PyTorch loss): objective to minimize\n        optimizer (PyTorch optimizier): optimizer to compute gradients of model parameters\n        dataloaders (PyTorch dataloader): dataloaders to iterate through\n        model_last_pth, model_best_pth (str ending in '.pt'): file path to save the model state dict\n        num_epochs (int): maximum number of training epochs\n\n    Returns\n    --------\n        model (PyTorch model): trained cnn with best weights\n    \"\"\"\n    \n    # Min validation loss\n    valid_loss_min = np.Inf\n    \n    # Main loop\n    for epoch in range(num_epochs):\n        print(f'Epoch {epoch+1} / {num_epochs}')\n        print('-' * 10)\n        \n        # Go through training and validation phase each epoch\n        for phase in ['train', 'val']:\n            if phase == 'train':\n                model.train()\n            else:\n                model.eval()\n            \n            # Keep track of loss and corrects each epoch\n            running_loss = 0.0\n            running_corrects = 0\n\n            # Training loop\n            for inputs, labels in dataloaders[phase]:\n                inputs, labels = inputs.to(device), labels.to(device)\n                \n                # Clear gradients\n                optimizer.zero_grad()\n                \n                # Predicted outputs and loss of gradients\n                with torch.set_grad_enabled(phase == 'train'):\n                    outputs = model(inputs)\n                    _, preds = torch.max(outputs, 1)\n                    loss = criterion(outputs, labels)\n\n                    # Backpropagation and update parameters\n                    if phase == 'train':\n                        loss.backward()\n                        optimizer.step()\n\n                # Update loss and number of correct predictions\n                running_loss += loss.item() * inputs.size(0)\n                running_corrects += torch.sum(preds == labels.data)\n            \n            # Step the scheduler if in training phase\n            if phase == 'train':\n                scheduler.step()\n            \n            # Calculate loss and accuracy of each epoch\n            epoch_loss = running_loss / dataset_sizes[phase]\n            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n            \n            \n            if phase == 'val':\n                if epoch_loss < valid_loss_min:\n                    valid_loss_min = epoch_loss\n                    torch.save(model.state_dict(), model_best_pth)\n            \n            print(f'{phase}\\t Loss: {epoch_loss:.4f}\\t Accuracy: {epoch_acc:.4f}')\n            \n            wandb.log({f'{phase}_loss': epoch_loss, f'{phase}_acc': epoch_acc})\n        \n        # Save model every epoch\n        torch.save(model.state_dict(), model_last_pth)\n\n    return model","metadata":{"execution":{"iopub.status.busy":"2024-05-21T12:32:27.453052Z","iopub.execute_input":"2024-05-21T12:32:27.453440Z","iopub.status.idle":"2024-05-21T12:32:27.467239Z","shell.execute_reply.started":"2024-05-21T12:32:27.453409Z","shell.execute_reply":"2024-05-21T12:32:27.466212Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"# Path to save model (last and best)\nmodel_last_pth = '/kaggle/working/resnet18-imagenet-01-last.pt'\nmodel_best_pth = '/kaggle/working/resnet18-imagenet-01-best.pt'\n\n# Saved model \nsaved_model_path = '/kaggle/input/resnet18-imagenet-01/pytorch/resnet18-imagenet-01/1/resnet18-ImageNet-0.pt'","metadata":{"execution":{"iopub.status.busy":"2024-05-21T12:32:51.908154Z","iopub.execute_input":"2024-05-21T12:32:51.908523Z","iopub.status.idle":"2024-05-21T12:32:51.913374Z","shell.execute_reply.started":"2024-05-21T12:32:51.908495Z","shell.execute_reply":"2024-05-21T12:32:51.912239Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"wandb.init(project='ImageProcessing-project', sync_tensorboard=True)\n\n# Load saved model\ntry:\n    model.load_state_dict(torch.load(saved_model_path))\n    print('Loaded saved model successfully')\nexcept FileNotFoundError:\n    print('File not found')\nexcept Exception as e:\n    print(f'An error occurred: {e}')\n\nprint()\n\nmodel.to(device)\n    \nmodel = train_model(model, criterion, optimizer, dataloaders, model_last_pth, model_best_pth, num_epochs)\n\nwandb.finish()","metadata":{"execution":{"iopub.status.busy":"2024-05-21T12:32:54.919557Z","iopub.execute_input":"2024-05-21T12:32:54.919909Z","iopub.status.idle":"2024-05-21T15:05:23.103538Z","shell.execute_reply.started":"2024-05-21T12:32:54.919881Z","shell.execute_reply":"2024-05-21T15:05:23.102500Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stderr","text":"2024-05-21 12:32:58.663982: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-05-21 12:32:58.664093: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-05-21 12:32:58.800825: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mntl09092004\u001b[0m (\u001b[33mtunglam994\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.17.0 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240521_123318-vgs0ilsr</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/tunglam994/ImageProcessing-project/runs/vgs0ilsr' target=\"_blank\">pious-yogurt-64</a></strong> to <a href='https://wandb.ai/tunglam994/ImageProcessing-project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/tunglam994/ImageProcessing-project' target=\"_blank\">https://wandb.ai/tunglam994/ImageProcessing-project</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/tunglam994/ImageProcessing-project/runs/vgs0ilsr' target=\"_blank\">https://wandb.ai/tunglam994/ImageProcessing-project/runs/vgs0ilsr</a>"},"metadata":{}},{"name":"stdout","text":"Loaded saved model successfully\n\nEpoch 1 / 100\n----------\ntrain\t Loss: 0.8591\t Accuracy: 0.8170\nval\t Loss: 0.6853\t Accuracy: 0.8448\nEpoch 2 / 100\n----------\ntrain\t Loss: 0.3425\t Accuracy: 0.9341\nval\t Loss: 0.5662\t Accuracy: 0.8728\nEpoch 3 / 100\n----------\ntrain\t Loss: 0.2100\t Accuracy: 0.9659\nval\t Loss: 0.5119\t Accuracy: 0.8865\nEpoch 4 / 100\n----------\ntrain\t Loss: 0.1385\t Accuracy: 0.9825\nval\t Loss: 0.4781\t Accuracy: 0.8894\nEpoch 5 / 100\n----------\ntrain\t Loss: 0.0954\t Accuracy: 0.9914\nval\t Loss: 0.4564\t Accuracy: 0.8922\nEpoch 6 / 100\n----------\ntrain\t Loss: 0.0703\t Accuracy: 0.9955\nval\t Loss: 0.4423\t Accuracy: 0.9009\nEpoch 7 / 100\n----------\ntrain\t Loss: 0.0563\t Accuracy: 0.9970\nval\t Loss: 0.4415\t Accuracy: 0.9001\nEpoch 8 / 100\n----------\ntrain\t Loss: 0.0453\t Accuracy: 0.9979\nval\t Loss: 0.4314\t Accuracy: 0.8987\nEpoch 9 / 100\n----------\ntrain\t Loss: 0.0437\t Accuracy: 0.9979\nval\t Loss: 0.4285\t Accuracy: 0.8994\nEpoch 10 / 100\n----------\ntrain\t Loss: 0.0425\t Accuracy: 0.9980\nval\t Loss: 0.4277\t Accuracy: 0.9030\nEpoch 11 / 100\n----------\ntrain\t Loss: 0.0419\t Accuracy: 0.9980\nval\t Loss: 0.4253\t Accuracy: 0.9023\nEpoch 12 / 100\n----------\ntrain\t Loss: 0.0416\t Accuracy: 0.9979\nval\t Loss: 0.4254\t Accuracy: 0.9023\nEpoch 13 / 100\n----------\ntrain\t Loss: 0.0410\t Accuracy: 0.9980\nval\t Loss: 0.4249\t Accuracy: 0.8994\nEpoch 14 / 100\n----------\ntrain\t Loss: 0.0407\t Accuracy: 0.9980\nval\t Loss: 0.4231\t Accuracy: 0.9023\nEpoch 15 / 100\n----------\ntrain\t Loss: 0.0394\t Accuracy: 0.9981\nval\t Loss: 0.4274\t Accuracy: 0.9016\nEpoch 16 / 100\n----------\ntrain\t Loss: 0.0393\t Accuracy: 0.9981\nval\t Loss: 0.4287\t Accuracy: 0.9001\nEpoch 17 / 100\n----------\ntrain\t Loss: 0.0395\t Accuracy: 0.9980\nval\t Loss: 0.4242\t Accuracy: 0.9009\nEpoch 18 / 100\n----------\ntrain\t Loss: 0.0395\t Accuracy: 0.9981\nval\t Loss: 0.4237\t Accuracy: 0.9023\nEpoch 19 / 100\n----------\ntrain\t Loss: 0.0394\t Accuracy: 0.9981\nval\t Loss: 0.4218\t Accuracy: 0.8980\nEpoch 20 / 100\n----------\ntrain\t Loss: 0.0394\t Accuracy: 0.9982\nval\t Loss: 0.4212\t Accuracy: 0.9016\nEpoch 21 / 100\n----------\ntrain\t Loss: 0.0392\t Accuracy: 0.9981\nval\t Loss: 0.4202\t Accuracy: 0.9037\nEpoch 22 / 100\n----------\ntrain\t Loss: 0.0393\t Accuracy: 0.9980\nval\t Loss: 0.4253\t Accuracy: 0.9023\nEpoch 23 / 100\n----------\ntrain\t Loss: 0.0391\t Accuracy: 0.9982\nval\t Loss: 0.4239\t Accuracy: 0.9023\nEpoch 24 / 100\n----------\ntrain\t Loss: 0.0391\t Accuracy: 0.9982\nval\t Loss: 0.4228\t Accuracy: 0.9001\nEpoch 25 / 100\n----------\ntrain\t Loss: 0.0391\t Accuracy: 0.9981\nval\t Loss: 0.4237\t Accuracy: 0.8987\nEpoch 26 / 100\n----------\ntrain\t Loss: 0.0391\t Accuracy: 0.9982\nval\t Loss: 0.4225\t Accuracy: 0.9045\nEpoch 27 / 100\n----------\ntrain\t Loss: 0.0391\t Accuracy: 0.9982\nval\t Loss: 0.4286\t Accuracy: 0.9016\nEpoch 28 / 100\n----------\ntrain\t Loss: 0.0392\t Accuracy: 0.9982\nval\t Loss: 0.4226\t Accuracy: 0.9030\nEpoch 29 / 100\n----------\ntrain\t Loss: 0.0394\t Accuracy: 0.9981\nval\t Loss: 0.4214\t Accuracy: 0.9001\nEpoch 30 / 100\n----------\ntrain\t Loss: 0.0392\t Accuracy: 0.9982\nval\t Loss: 0.4218\t Accuracy: 0.9001\nEpoch 31 / 100\n----------\ntrain\t Loss: 0.0393\t Accuracy: 0.9981\nval\t Loss: 0.4282\t Accuracy: 0.9023\nEpoch 32 / 100\n----------\ntrain\t Loss: 0.0393\t Accuracy: 0.9981\nval\t Loss: 0.4251\t Accuracy: 0.9023\nEpoch 33 / 100\n----------\ntrain\t Loss: 0.0392\t Accuracy: 0.9981\nval\t Loss: 0.4225\t Accuracy: 0.9023\nEpoch 34 / 100\n----------\ntrain\t Loss: 0.0393\t Accuracy: 0.9981\nval\t Loss: 0.4190\t Accuracy: 0.9045\nEpoch 35 / 100\n----------\ntrain\t Loss: 0.0393\t Accuracy: 0.9981\nval\t Loss: 0.4244\t Accuracy: 0.9030\nEpoch 36 / 100\n----------\ntrain\t Loss: 0.0389\t Accuracy: 0.9982\nval\t Loss: 0.4246\t Accuracy: 0.9023\nEpoch 37 / 100\n----------\ntrain\t Loss: 0.0390\t Accuracy: 0.9982\nval\t Loss: 0.4237\t Accuracy: 0.9030\nEpoch 38 / 100\n----------\ntrain\t Loss: 0.0392\t Accuracy: 0.9981\nval\t Loss: 0.4258\t Accuracy: 0.9030\nEpoch 39 / 100\n----------\ntrain\t Loss: 0.0390\t Accuracy: 0.9982\nval\t Loss: 0.4266\t Accuracy: 0.9045\nEpoch 40 / 100\n----------\ntrain\t Loss: 0.0391\t Accuracy: 0.9981\nval\t Loss: 0.4249\t Accuracy: 0.9023\nEpoch 41 / 100\n----------\ntrain\t Loss: 0.0392\t Accuracy: 0.9981\nval\t Loss: 0.4200\t Accuracy: 0.9009\nEpoch 42 / 100\n----------\ntrain\t Loss: 0.0389\t Accuracy: 0.9981\nval\t Loss: 0.4198\t Accuracy: 0.9016\nEpoch 43 / 100\n----------\ntrain\t Loss: 0.0391\t Accuracy: 0.9982\nval\t Loss: 0.4226\t Accuracy: 0.9016\nEpoch 44 / 100\n----------\ntrain\t Loss: 0.0392\t Accuracy: 0.9982\nval\t Loss: 0.4241\t Accuracy: 0.9001\nEpoch 45 / 100\n----------\ntrain\t Loss: 0.0391\t Accuracy: 0.9980\nval\t Loss: 0.4245\t Accuracy: 0.9030\nEpoch 46 / 100\n----------\ntrain\t Loss: 0.0392\t Accuracy: 0.9980\nval\t Loss: 0.4216\t Accuracy: 0.9037\nEpoch 47 / 100\n----------\ntrain\t Loss: 0.0393\t Accuracy: 0.9981\nval\t Loss: 0.4251\t Accuracy: 0.9023\nEpoch 48 / 100\n----------\ntrain\t Loss: 0.0392\t Accuracy: 0.9981\nval\t Loss: 0.4231\t Accuracy: 0.9009\nEpoch 49 / 100\n----------\ntrain\t Loss: 0.0391\t Accuracy: 0.9982\nval\t Loss: 0.4265\t Accuracy: 0.9023\nEpoch 50 / 100\n----------\ntrain\t Loss: 0.0392\t Accuracy: 0.9981\nval\t Loss: 0.4185\t Accuracy: 0.9016\nEpoch 51 / 100\n----------\ntrain\t Loss: 0.0390\t Accuracy: 0.9981\nval\t Loss: 0.4197\t Accuracy: 0.9023\nEpoch 52 / 100\n----------\ntrain\t Loss: 0.0392\t Accuracy: 0.9982\nval\t Loss: 0.4256\t Accuracy: 0.9023\nEpoch 53 / 100\n----------\ntrain\t Loss: 0.0392\t Accuracy: 0.9981\nval\t Loss: 0.4248\t Accuracy: 0.9030\nEpoch 54 / 100\n----------\ntrain\t Loss: 0.0392\t Accuracy: 0.9981\nval\t Loss: 0.4223\t Accuracy: 0.9030\nEpoch 55 / 100\n----------\ntrain\t Loss: 0.0391\t Accuracy: 0.9982\nval\t Loss: 0.4203\t Accuracy: 0.9023\nEpoch 56 / 100\n----------\ntrain\t Loss: 0.0392\t Accuracy: 0.9981\nval\t Loss: 0.4217\t Accuracy: 0.9009\nEpoch 57 / 100\n----------\ntrain\t Loss: 0.0393\t Accuracy: 0.9982\nval\t Loss: 0.4196\t Accuracy: 0.9037\nEpoch 58 / 100\n----------\ntrain\t Loss: 0.0392\t Accuracy: 0.9981\nval\t Loss: 0.4241\t Accuracy: 0.9037\nEpoch 59 / 100\n----------\ntrain\t Loss: 0.0389\t Accuracy: 0.9982\nval\t Loss: 0.4247\t Accuracy: 0.9001\nEpoch 60 / 100\n----------\ntrain\t Loss: 0.0391\t Accuracy: 0.9981\nval\t Loss: 0.4220\t Accuracy: 0.9030\nEpoch 61 / 100\n----------\ntrain\t Loss: 0.0393\t Accuracy: 0.9981\nval\t Loss: 0.4251\t Accuracy: 0.9045\nEpoch 62 / 100\n----------\ntrain\t Loss: 0.0389\t Accuracy: 0.9981\nval\t Loss: 0.4224\t Accuracy: 0.9016\nEpoch 63 / 100\n----------\ntrain\t Loss: 0.0390\t Accuracy: 0.9982\nval\t Loss: 0.4247\t Accuracy: 0.9030\nEpoch 64 / 100\n----------\ntrain\t Loss: 0.0392\t Accuracy: 0.9981\nval\t Loss: 0.4243\t Accuracy: 0.9030\nEpoch 65 / 100\n----------\ntrain\t Loss: 0.0390\t Accuracy: 0.9981\nval\t Loss: 0.4242\t Accuracy: 0.9001\nEpoch 66 / 100\n----------\ntrain\t Loss: 0.0391\t Accuracy: 0.9981\nval\t Loss: 0.4244\t Accuracy: 0.9030\nEpoch 67 / 100\n----------\ntrain\t Loss: 0.0392\t Accuracy: 0.9981\nval\t Loss: 0.4269\t Accuracy: 0.9023\nEpoch 68 / 100\n----------\ntrain\t Loss: 0.0393\t Accuracy: 0.9981\nval\t Loss: 0.4209\t Accuracy: 0.9030\nEpoch 69 / 100\n----------\ntrain\t Loss: 0.0390\t Accuracy: 0.9981\nval\t Loss: 0.4219\t Accuracy: 0.9009\nEpoch 70 / 100\n----------\ntrain\t Loss: 0.0391\t Accuracy: 0.9981\nval\t Loss: 0.4197\t Accuracy: 0.9009\nEpoch 71 / 100\n----------\ntrain\t Loss: 0.0390\t Accuracy: 0.9981\nval\t Loss: 0.4244\t Accuracy: 0.8994\nEpoch 72 / 100\n----------\ntrain\t Loss: 0.0393\t Accuracy: 0.9981\nval\t Loss: 0.4235\t Accuracy: 0.9016\nEpoch 73 / 100\n----------\ntrain\t Loss: 0.0390\t Accuracy: 0.9981\nval\t Loss: 0.4211\t Accuracy: 0.9023\nEpoch 74 / 100\n----------\ntrain\t Loss: 0.0392\t Accuracy: 0.9982\nval\t Loss: 0.4228\t Accuracy: 0.9016\nEpoch 75 / 100\n----------\ntrain\t Loss: 0.0393\t Accuracy: 0.9981\nval\t Loss: 0.4221\t Accuracy: 0.9037\nEpoch 76 / 100\n----------\ntrain\t Loss: 0.0390\t Accuracy: 0.9982\nval\t Loss: 0.4220\t Accuracy: 0.9016\nEpoch 77 / 100\n----------\ntrain\t Loss: 0.0391\t Accuracy: 0.9981\nval\t Loss: 0.4254\t Accuracy: 0.9023\nEpoch 78 / 100\n----------\ntrain\t Loss: 0.0393\t Accuracy: 0.9981\nval\t Loss: 0.4216\t Accuracy: 0.9023\nEpoch 79 / 100\n----------\ntrain\t Loss: 0.0392\t Accuracy: 0.9981\nval\t Loss: 0.4228\t Accuracy: 0.9016\nEpoch 80 / 100\n----------\ntrain\t Loss: 0.0392\t Accuracy: 0.9981\nval\t Loss: 0.4214\t Accuracy: 0.9016\nEpoch 81 / 100\n----------\ntrain\t Loss: 0.0393\t Accuracy: 0.9980\nval\t Loss: 0.4239\t Accuracy: 0.9009\nEpoch 82 / 100\n----------\ntrain\t Loss: 0.0393\t Accuracy: 0.9982\nval\t Loss: 0.4259\t Accuracy: 0.9016\nEpoch 83 / 100\n----------\ntrain\t Loss: 0.0393\t Accuracy: 0.9981\nval\t Loss: 0.4230\t Accuracy: 0.9030\nEpoch 84 / 100\n----------\ntrain\t Loss: 0.0393\t Accuracy: 0.9980\nval\t Loss: 0.4228\t Accuracy: 0.9037\nEpoch 85 / 100\n----------\ntrain\t Loss: 0.0393\t Accuracy: 0.9981\nval\t Loss: 0.4201\t Accuracy: 0.9023\nEpoch 86 / 100\n----------\ntrain\t Loss: 0.0394\t Accuracy: 0.9980\nval\t Loss: 0.4264\t Accuracy: 0.9030\nEpoch 87 / 100\n----------\ntrain\t Loss: 0.0390\t Accuracy: 0.9980\nval\t Loss: 0.4261\t Accuracy: 0.9001\nEpoch 88 / 100\n----------\ntrain\t Loss: 0.0393\t Accuracy: 0.9982\nval\t Loss: 0.4217\t Accuracy: 0.9009\nEpoch 89 / 100\n----------\ntrain\t Loss: 0.0394\t Accuracy: 0.9981\nval\t Loss: 0.4244\t Accuracy: 0.8994\nEpoch 90 / 100\n----------\ntrain\t Loss: 0.0392\t Accuracy: 0.9980\nval\t Loss: 0.4208\t Accuracy: 0.9016\nEpoch 91 / 100\n----------\ntrain\t Loss: 0.0392\t Accuracy: 0.9982\nval\t Loss: 0.4187\t Accuracy: 0.9016\nEpoch 92 / 100\n----------\ntrain\t Loss: 0.0393\t Accuracy: 0.9980\nval\t Loss: 0.4232\t Accuracy: 0.9023\nEpoch 93 / 100\n----------\ntrain\t Loss: 0.0391\t Accuracy: 0.9982\nval\t Loss: 0.4245\t Accuracy: 0.9001\nEpoch 94 / 100\n----------\ntrain\t Loss: 0.0393\t Accuracy: 0.9981\nval\t Loss: 0.4261\t Accuracy: 0.9023\nEpoch 95 / 100\n----------\ntrain\t Loss: 0.0389\t Accuracy: 0.9981\nval\t Loss: 0.4225\t Accuracy: 0.8994\nEpoch 96 / 100\n----------\ntrain\t Loss: 0.0392\t Accuracy: 0.9981\nval\t Loss: 0.4230\t Accuracy: 0.9001\nEpoch 97 / 100\n----------\ntrain\t Loss: 0.0391\t Accuracy: 0.9981\nval\t Loss: 0.4224\t Accuracy: 0.9009\nEpoch 98 / 100\n----------\ntrain\t Loss: 0.0392\t Accuracy: 0.9982\nval\t Loss: 0.4226\t Accuracy: 0.9037\nEpoch 99 / 100\n----------\ntrain\t Loss: 0.0393\t Accuracy: 0.9980\nval\t Loss: 0.4231\t Accuracy: 0.9030\nEpoch 100 / 100\n----------\ntrain\t Loss: 0.0393\t Accuracy: 0.9980\nval\t Loss: 0.4224\t Accuracy: 0.9001\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train_acc</td><td>▁▇██████████████████████████████████████</td></tr><tr><td>train_loss</td><td>█▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc</td><td>▁▆█▇█▇▇██████████▇█████▇██████████▇▇███▇</td></tr><tr><td>val_loss</td><td>█▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train_acc</td><td>0.99803</td></tr><tr><td>train_loss</td><td>0.03934</td></tr><tr><td>val_acc</td><td>0.90014</td></tr><tr><td>val_loss</td><td>0.42239</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">pious-yogurt-64</strong> at: <a href='https://wandb.ai/tunglam994/ImageProcessing-project/runs/vgs0ilsr' target=\"_blank\">https://wandb.ai/tunglam994/ImageProcessing-project/runs/vgs0ilsr</a><br/> View project at: <a href='https://wandb.ai/tunglam994/ImageProcessing-project' target=\"_blank\">https://wandb.ai/tunglam994/ImageProcessing-project</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20240521_123318-vgs0ilsr/logs</code>"},"metadata":{}}]},{"cell_type":"code","source":"#Load saved model\nmodel.load_state_dict(torch.load('/kaggle/working/resnet18-ImageNet-0.pt'))","metadata":{},"execution_count":null,"outputs":[]}]}