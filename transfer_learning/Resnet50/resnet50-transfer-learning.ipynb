{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":8357046,"sourceType":"datasetVersion","datasetId":4966083},{"sourceId":8377223,"sourceType":"datasetVersion","datasetId":4981244}],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.optim import lr_scheduler\n\nimport numpy as np\nimport torchvision\nfrom torchvision import datasets, models, transforms\n\nimport time\nimport os\nfrom PIL import Image\nfrom tempfile import TemporaryDirectory\n\nfrom torch.utils.data import DataLoader, SubsetRandomSampler\nimport random\nfrom torch.utils.data import random_split\n\n!wandb login 2a9ca7406b5b4c61d59f0f3606a221268edc9ca8\nimport wandb\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"save_model_path = '/kaggle/working/ResNet50_customed_4_augument.pt'","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nprint(device)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nfrom PIL import Image\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms\n\nclass CustomDataset(Dataset):\n    def __init__(self, data_dir, transform=None):\n        self.data_dir = data_dir\n        self.transform = transform\n        self.classes = self._find_classes()\n        self.image_paths, self.labels = self._load_data()\n\n    def _find_classes(self):\n        classes = sorted([d for d in os.listdir(self.data_dir) if os.path.isdir(os.path.join(self.data_dir, d))])\n        return classes\n\n    def _load_data(self):\n        image_paths = []\n        labels = []\n        for label in self.classes:\n            class_dir = os.path.join(self.data_dir, label)\n            for img_name in os.listdir(class_dir):\n                img_path = os.path.join(class_dir, img_name)\n                image_paths.append(img_path)\n                labels.append(int(label))\n        return image_paths, labels\n\n    def __len__(self):\n        return len(self.image_paths)\n\n    def __getitem__(self, idx):\n        img_path = self.image_paths[idx]\n        label = self.labels[idx]\n        label = int (label)\n        image = Image.open(img_path).convert(\"RGB\")\n        if self.transform:\n            image = self.transform(image)\n        return image, label","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data_dir = '/kaggle/input/augument-dataset/wb_recognition_dataset/train/images'\nval_data_dir = '/kaggle/input/augument-dataset/wb_recognition_dataset/val/images'\n\nnormalize = transforms.Normalize(mean=[0.56,0.56,0.535], std=[0.02,0.02,0.02])\n\ntrain_transform = transforms.Compose([\n    transforms.Resize((224, 224)),\n#     transforms.RandomRotation(degrees=15),\n#     transforms.ColorJitter(),\n    transforms.ToTensor(),\n    normalize\n])\n\nval_transform = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n    normalize\n])\n\ntrain_dataset = CustomDataset(data_dir=train_data_dir, transform=train_transform)\nval_dataset = CustomDataset(data_dir=val_data_dir, transform=val_transform)\n\nimage_datasets = {\"train\":train_dataset, \"val\": val_dataset}\n\ntrain_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers = 4, pin_memory = True)\nval_loader = DataLoader(val_dataset, batch_size=32, shuffle=False,num_workers = 4, pin_memory = True)\n\ndataloader = {\"train\": train_loader, \"val\": val_loader}\n\ndataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\nprint (dataset_sizes['train'])\nprint (dataset_sizes['val'])\nprint (len(image_datasets['val'].classes))\n# for images, labels in dataloader[\"train\"]:\n#     images, labels = images.to(device), labels.to(device)\n#     # Now `images` and `labels` are moved to CUDA if available\n\n# # Similarly for validation data loader\n# for images, labels in dataloader[\"val\"]:\n#     images, labels = images.to(device), labels.to(device)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = torchvision.models.resnet50(weights='IMAGENET1K_V2')\n# Parameters of newly constructed modules have requires_grad=True by default\nnum_ftrs = model.fc.in_features\nmodel.fc = nn.Linear(num_ftrs, 2139)\n\nfor param in model.parameters():\n    param.requires_grad = False\nfor param in model.fc.parameters():\n    param.requires_grad = True\n\nmodel = model.to(device)\n\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=0.001)\n\n# # Decay LR by a factor of 0.1 every 7 epochs\nscheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ndef train_model(model, criterion, optimizer, scheduler, num_epochs, save_model_path, dataloader):\n\n    for epoch in range(num_epochs):\n        print(f'Epoch {epoch}/{num_epochs - 1}')\n        print('-' * 10)\n\n        # Each epoch has a training and validation phase\n        for phase in ['train', 'val']:\n            if phase == 'train':\n                model.train()  # Set model to training mode\n            else:\n                model.eval()   # Set model to evaluate mode\n\n            running_loss = 0.0\n            running_corrects = 0\n\n            # Iterate over data.\n            for inputs, labels in dataloader[phase]:\n                \n                inputs = inputs.to(device)\n                labels = labels.to(device)\n\n                # zero the parameter gradients\n                optimizer.zero_grad()\n\n                # forward\n                # track history if only in train\n                with torch.set_grad_enabled(phase == 'train'):\n                    outputs = model(inputs)\n                    _, preds = torch.max(outputs, 1)\n                    loss = criterion(outputs, labels)\n\n                    # backward + optimize only if in training phase\n                    if phase == 'train':\n                        loss.backward()\n                        optimizer.step()\n\n                # statistics\n                running_loss += loss.item() * inputs.size(0)\n                running_corrects += torch.sum(preds == labels.data)\n#             if phase == 'train':\n#                 scheduler.step()\n\n            epoch_loss = running_loss / dataset_sizes[phase]\n            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n\n            print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n            phase_acc, phase_loss = phase + \"acc\", phase + \"loss\"\n            wandb.log({str(phase_acc): epoch_acc, str(phase_loss):epoch_loss})\n        torch.save(model.state_dict(), save_model_path)\n    return model","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nwandb.init(project='ImageProcessing-project', sync_tensorboard=True)\ntry:\n    model.load_state_dict(torch.load(save_model_path))\nexcept:\n    f = open(save_model_path, 'w')\n    print(\"initial file\")\n\nmodel = train_model(model, criterion, optimizer, scheduler,\n                       300, save_model_path, dataloader)\nwandb.finish()","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}